<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>feed流 | 微信朋友圈如何实现的</title>
      <link href="/2024/05/08/15-Feed/"/>
      <url>/2024/05/08/15-Feed/</url>
      
        <content type="html"><![CDATA[<h1 id="什么是Feed流"><a href="#什么是Feed流" class="headerlink" title="什么是Feed流"></a>什么是Feed流</h1><p>比如微博，B站刷视频，不停刷会一直有信息涌现。就像给宠物喂食物一样，只要吃光了就一直加，故此称之为Feed（喂养）。 Feed流包含以下两种：</p><ul><li>基于关注并按照时间排序，比如朋友圈，微博关注列表<ul><li>关注Timeline</li><li>个人Timeline，存放自己发送过的，比如微博个人首页，自己发送的</li></ul></li><li>基于算法推荐的，比如视频，微博推流</li></ul><p>实际场景：</p><ul><li>朋友圈，微博关注列表</li><li>刷视频，微博推流</li></ul><h1 id="推拉模型"><a href="#推拉模型" class="headerlink" title="推拉模型"></a>推拉模型</h1><h2 id="拉模型-读扩散"><a href="#拉模型-读扩散" class="headerlink" title="拉模型 &#x2F; 读扩散"></a>拉模型 &#x2F; 读扩散</h2><p>基本步骤：</p><ul><li>先查询用户关注的创作者uid</li><li>根据uid查询所有发布文章</li><li>按照发布时间降序排列，选择一定数量的文章，作为Timeline返回</li></ul><p>使用拉模型方案用户每打开一次「关注页」系统就需要读取 N 个人的文章（N 为用户关注的作者数）, 因此拉模型也被称为<strong>读扩散</strong>，具有以下特点：</p><ul><li>拉模型不需要存储额外的数据，实现简单</li><li>缺点每次阅读关注页，都需要大量读取和一次重新排序操作，如果用户关注人数比较多，一次拉取耗时比较长，影响用户体验</li></ul><aside> 💡 一次全量拉取 + 一次排序，返回有限数据</aside><h2 id="推模型-写扩散"><a href="#推模型-写扩散" class="headerlink" title="推模型 &#x2F; 写扩散"></a>推模型 &#x2F; 写扩散</h2><p>基本步骤：</p><ul><li>创作者发布文章时，推送新文章到粉丝关注的Timeline，又称为<strong>写扩散</strong></li><li>用户读取Timeline，不需要取逐个拉取关注列表再排序，体验好</li></ul><p>但是当粉丝量大时，每次推送数据的写入量巨大，可以通过MQ来实现向粉丝的TimeLine异步推送，实现相对拉模型，复杂一些。</p><aside> 💡 微信朋友圈实际采用写扩散形式，读扩散打开时cpu压力过大，使用比较少</aside><h2 id="在线推，离线拉"><a href="#在线推，离线拉" class="headerlink" title="在线推，离线拉"></a>在线推，离线拉</h2><p>对于拉模型，当关注数量多时，读取 + 排序是一个重操作，对于用户体验很差。</p><p>对于推模型，写入量较大。</p><p>针对上述两点，针对活跃用户采用推模型，非活跃用户登陆后利用拉模型重新构建关注的Timeline，并且可以设置过期时间释放Timeline释放资源。</p><h1 id="存储优化"><a href="#存储优化" class="headerlink" title="存储优化"></a>存储优化</h1><h2 id="ZSet"><a href="#ZSet" class="headerlink" title="ZSet"></a>ZSet</h2><ul><li>存储上可以利用Redis减轻MySQL压力，并且Redis支持有序结构，非活跃用户数据也会过期释放</li><li>将Timeline缓存在Redis中，利用ZSet有序性可以实现按照时间、点赞数的拉取，并且基于ZSet可以达到去重</li><li>将article_id作为ZSet的member，发布时间戳、点赞数作为score，实现不同的Timeline</li><li>在推送新Feed的时候，对目标的Timeline的SortedSet进行ZAdd操作，如缓存里没有使用拉模型重建</li><li>用户刷取视频，从ZSet中通过ZRange拉取id，再根据id获取具体title，url等信息</li></ul><h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><p>当Redis不存在Timeline缓存，无法判断是缓存失效还是用户Timeline为空，需要重复读数据库判断。</p><p>可以在ZSet中存放NoMore的标志，避免数据库也没有更多的数据，频繁查询数据库，造成的缓存击穿。</p><h2 id="多层缓存"><a href="#多层缓存" class="headerlink" title="多层缓存"></a>多层缓存</h2><p>Redis作为NoSQL存放在内存中，存储数据是有限的，考虑使用其他有序结构数据库构建多级缓存。</p><p>实际拉取数据一般会拉取超额的数量，利用本地内存，避免高频查询请求</p><h1 id="细节处理"><a href="#细节处理" class="headerlink" title="细节处理"></a>细节处理</h1><h2 id="分页器"><a href="#分页器" class="headerlink" title="分页器"></a>分页器</h2><p>Feed是一个动态列表，随着时间变化不断变化，传统的Limit + offset会导致拉取重复的文章</p><p>一般还是用feed流最后一条记录的时间戳来拉取指定记录，同时在生成score的同时用时间戳 + id做拼接，在不影响排序的前提下避免重复</p><p>（在拉取请求时会返回最后一条记录的时间戳）</p><h2 id="大规模推送"><a href="#大规模推送" class="headerlink" title="大规模推送"></a>大规模推送</h2><p>同时推送大批量任务，可能导致单机Worker过载；可以将任务拆分成多个子任务，通过消息队列发送到多台MQ worker上进行处理，失败也只需要局部重试</p><h1 id="如何设计一个微信朋友圈那样的系统"><a href="#如何设计一个微信朋友圈那样的系统" class="headerlink" title="如何设计一个微信朋友圈那样的系统"></a>如何设计一个微信朋友圈那样的系统</h1><ul><li>设计数据库的表，列出主要的字段<ul><li>一张关系列表，包含了用户的好友列表，id，friend_id</li><li>一张pyq文章列表，包含了content，author_id，publicTime</li><li>可以按照时间分库分表</li></ul></li><li>为了提升快速朋友圈打开，显示文章速度<ul><li>可以利用缓存，存储相关的文章id，使用Redis的ZSet结构，实现基于时间的关注列表</li><li>好友发布新的朋友圈，推送到对应的好友的ZSet列表中（存在的），通过ZAdd添加，member为id，score为时间戳</li><li>设置一定过期时间，当用户第一次打开朋友圈时，利用拉模型重新构建缓存Timeline，过期删除释放资源；查询好友id，再查询好友发布id，做一次排序，返回有限的数据</li></ul></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 场景 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker是什么</title>
      <link href="/2023/10/20/13-Docker/"/>
      <url>/2023/10/20/13-Docker/</url>
      
        <content type="html"><![CDATA[<blockquote><p><a href="https://www.bilibili.com/video/BV14s4y1i7Vf?p=1&vd_source=98edb319e59affabde4d9cb2731826cd">GeekHour Docker入门教程</a></p></blockquote><h2 id="Docker和虚拟机区别"><a href="#Docker和虚拟机区别" class="headerlink" title="Docker和虚拟机区别"></a>Docker和虚拟机区别</h2><p>虚拟机是物理机通过Hypervisor虚拟化技术实现的，将物理机器虚拟成多个虚拟化的服务器，虚拟化的服务器包含了完整的操作系统、CPU、硬盘等资源。</p><p>Docker是容器一种实现，容器是一种虚拟化技术。和虚拟机类似，可以在这个虚拟环境中运行程序，但是使用宿主机的操作系统，占用较少的资源。</p><h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p><img src="/../images/docker1.png" alt="image-20231025220228605"></p><ul><li>images：一个只读的模板，可以用来创建容器。</li><li>container：docker运行的实例，提供一个独立可以移植的环境。</li><li>registry：仓库集中存储分享docker镜像，比如dockerhub。</li><li>docker-daemon：服务端守护进程，管理docker资源，处理请求返回给客户端。</li><li>docker-client：发送请求。</li></ul><h2 id="Docker基本使用"><a href="#Docker基本使用" class="headerlink" title="Docker基本使用"></a>Docker基本使用</h2><h3 id="创建Dockerfile"><a href="#创建Dockerfile" class="headerlink" title="创建Dockerfile"></a>创建Dockerfile</h3><pre class=" language-dockerfile"><code class="language-dockerfile">FROM node: 18-alpine # 精简的操作系统WORKDIR /appCOPY ..RUN npm installCMD node src/index.jsEXPOSE 3000</code></pre><pre class=" language-shell"><code class="language-shell">docker build -t hello-docker:1.1 .# hello-docker是image-name, 可以指定版本号，'.'当前路径# 生成的docker-image </code></pre><h3 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h3><pre class=" language-shell"><code class="language-shell">docker image ls # 查看所有镜像docker run hello-docker # 运行镜像docker pull geekHour/hello-docker # 拉取镜像</code></pre><h2 id="Docker-Compose-yaml"><a href="#Docker-Compose-yaml" class="headerlink" title="Docker.Compose.yaml"></a>Docker.Compose.yaml</h2><p>自动配置相互关联的容器，使用<code>docker compose up</code>启动、停止、重建服务。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 是什么 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Bitcask | 实现细节</title>
      <link href="/2023/10/08/8-Bitcask-1/"/>
      <url>/2023/10/08/8-Bitcask-1/</url>
      
        <content type="html"><![CDATA[<h2 id="数据库启动流程"><a href="#数据库启动流程" class="headerlink" title="数据库启动流程"></a>数据库启动流程</h2><p>基于Bitcask论文实现的存储引擎实例，本质上是在本地当中维护一个文件夹，这其中包含了.data结尾的数据文件，merge完成的Hint文件，文件锁文件等。</p><h3 id="参数校验"><a href="#参数校验" class="headerlink" title="参数校验"></a>参数校验</h3><p>启动Bitcask时做参数校验应该考虑：</p><ul><li>当前目录是否存在，是否为一个新的实例</li><li>对于DataFile、MergeRatio的参数合法性校验</li></ul><h3 id="文件锁"><a href="#文件锁" class="headerlink" title="文件锁"></a>文件锁</h3><p>在原文当中Bitcask提出可由多个进程同时读，但是只能由一个进程写，在实际实现中为了避免并发问题，只允许一个进程进行读写操作，相当于只允许打开一个服务端。</p><p>通过系统调用flock提供的文件锁，保证多个进程之间的互斥，在启动数据库时，通过判断是否能够获取对应文件锁，来保证单个进程运行数据库。</p><h3 id="初始化DB实例"><a href="#初始化DB实例" class="headerlink" title="初始化DB实例"></a>初始化DB实例</h3><p>主要包含了以下参数：</p><ul><li>配置参数</li><li>读写锁</li><li>旧的文件（只读，不写入）</li><li>索引</li><li>是否初始化</li><li>文件锁</li></ul><h3 id="加载merge文件"><a href="#加载merge文件" class="headerlink" title="加载merge文件"></a>加载merge文件</h3><p>merge后的文件目录存放在父级目录同名之下的文件夹当中，如果不存在说明没有发生过合并。</p><p>如果存在merge目录，遍历目录下的文件，判断是否存在mergeFinished文件，来判断merge操作是否有效，mergeFinished文件中存放了完成merge的文件序列号，未完成merge的部分后续需要手动加载索引信息。</p><p>在判断merge有效性后，删除旧文件，移动新文件到目录当中覆盖，最后删除merge目录。</p><h3 id="加载数据文件"><a href="#加载数据文件" class="headerlink" title="加载数据文件"></a>加载数据文件</h3><p>因为内存中维护的是key-value的数据信息在磁盘中的位置，这里需要提前加载好数据文件，每次打开数据库都需要重新构造索引信息，查询时先从内存中找到位置信息，再从文件中读取。</p><p>在本项目中将.data后缀的文件作为数据文件，并且这里根据文件名排序，实现有序数据文件，便于后续有序加载索引（记录是追加写入到磁盘中的文件的，相同Key的记录，后加载应该是最新的有效数据，用来更新已经加载的数据）。</p><p>在加载数据文件时，加载文件的名，作为后续olderFiles的编号。</p><p>加载到最后一个文件，是当前实例的活跃文件，所有新增或者删除记录都是追加写入到活跃文件当中的，其他文件作为olderFile只用于读。</p><h3 id="加载索引"><a href="#加载索引" class="headerlink" title="加载索引"></a>加载索引</h3><p>在磁盘中当中只保存了数据文件，每次打开数据库是需要重新加载索引信息到内存当中的。当然如果此时发生了merge操作，merge操作完会生成所有有效信息的一个Hint索引文件，未merge的数据文件还需要手动构造加载索引信息。</p><p>读取数据文件中的每一条记录，进行解码得到信息，构造Value信息：</p><ul><li>解析记录的末尾序列号，如果是nonTransactionSeqNo说明是普通记录，可以更新</li><li>如果是事务ID，暂存记录到内存中，直到读取到事务ID结束的记录，加载这些记录到内存当中</li><li>记录最新的事务序列号，加载到DB实例当中，保证后续全局唯一</li><li>注意最后一个文件的末尾信息offset，作为活跃文件当前文件写入位置信息writeoff需要记录</li></ul><p>在解析完Key后，如果是普通索引，或者完整事务记录信息，更新内存索引，Key：key，Value：Fid + Offset + size。</p><p>如果序列号是事务序列号，需要判断是否完成，完成统一加载索引信息，否则丢弃。</p><p>其中B+树索引，使用了开源的BBlot，索引信息实际上是维护一个DB实例。每次加载数据库时，索引信息不需要通过数据文件加载，直接打开DB实例即可。由于没有读取数据文件，最新的事务序列号要通过一个seqNoFile文件进行获取，同时为了后续追加写入读取完后删除，在关闭数据库时写入一条记录到seqNoFile文件当中。</p><h2 id="索引结构设计"><a href="#索引结构设计" class="headerlink" title="索引结构设计"></a>索引结构设计</h2><p>在内存当中，我们需要一种支持高效插入、读取、删除数据的结构，并且如果需要数据高效遍历的话，我们最好是选择天然支持有序的一种结构。常见的选择有BTree、跳表、红黑树等。</p><p>在设计内存索引结构时，考虑到实际场景需要实现不同的内存索引结构，设计了抽象的内存索引接口：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">type</span> Indexer <span class="token keyword">interface</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// Put 向索引结构中存储 key 对应的数据位置信息</span>    <span class="token function">Put</span><span class="token punctuation">(</span>key <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span><span class="token punctuation">,</span> pos <span class="token operator">*</span>data<span class="token punctuation">.</span>LogRecordPos<span class="token punctuation">)</span> <span class="token operator">*</span>data<span class="token punctuation">.</span>LogRecordPos    <span class="token comment" spellcheck="true">// Get 从索引结构中获取 key 对应的数据位置信息</span>    <span class="token function">Get</span><span class="token punctuation">(</span>key <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span><span class="token punctuation">)</span> <span class="token operator">*</span>data<span class="token punctuation">.</span>LogRecordPos    <span class="token comment" spellcheck="true">// Delete 从索引结构中删除 key 对应的数据位置信息</span>    <span class="token function">Delete</span><span class="token punctuation">(</span>key <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span><span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token operator">*</span>data<span class="token punctuation">.</span>LogRecordPos<span class="token punctuation">,</span> <span class="token builtin">bool</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// Size 索引中数据量</span>    <span class="token function">Size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token builtin">int</span>    <span class="token comment" spellcheck="true">// Iterator 获取索引结构的迭代器</span>    <span class="token function">Iterator</span><span class="token punctuation">(</span>reverse <span class="token builtin">bool</span><span class="token punctuation">)</span> Iterator    <span class="token comment" spellcheck="true">// Close 关闭索引</span>    <span class="token function">Close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token builtin">error</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><p>在本项目中，主要结合Bitcask论文实现存储引擎实例，索引部分设计不是重点，主要利用现有的索引实现相应的功能。主要采用了三种索引结构，BTree，ARTree以及B+Tree。</p><h3 id="BTree"><a href="#BTree" class="headerlink" title="BTree"></a>BTree</h3><p>在一开始中只是先使用<a href="https://github.com/google/btree">BTree</a>实现了，BTree是一种常用的多叉树数据结构，主要用于管理大量数据并允许高效的插入、删除和搜索操作。具有以下特点：</p><ul><li><strong>多叉树结构</strong>：B树是一种多叉树，每个节点可以拥有多个子节点，通常用于处理大量数据，减少树的高度。</li><li><strong>平衡性</strong>：B树是一种自平衡树，保持平衡是其重要特征，通过旋转和分裂等操作保持树的平衡，确保操作的时间复杂度稳定。</li><li><strong>有序存储</strong>：B树节点中的元素是有序存储的，使得在节点内部可以进行快速查找。</li></ul><h3 id="ARTree"><a href="#ARTree" class="headerlink" title="ARTree"></a>ARTree</h3><p>ARTree是自适应基树，可以看成是一个前缀树的优化版本，如果子节点只有一个值，则会和父节点进行合并，减少空间占用。实际中使用了封装<a href="https://github.com/plar/go-adaptive-radix-tree">go-adaptive</a>实现ART索引结构。</p><p>ARTree节点有多个类型，比如Node4，Node16。对于Node4：使用一个长度为4的数组来存储子节点的键，另外一个长度为4的数组来存储指向子节点的指针。</p><p>随着键的插入和删除，节点可能需要进行升级或降级以匹配子节点的数量。通过动态调整子节点的大小，实现空间的高效利用和查询性能优化。</p><h3 id="B-Tree"><a href="#B-Tree" class="headerlink" title="B+Tree"></a>B+Tree</h3><p>从 bitcask 论文中可以得知，Bitcask存储模型的最大特点是所有的索引都只能在内存中维护，这样的特性带来了一个好处，维护在内存中的索引信息<strong>一次磁盘 IO 操作就可以拿到数据</strong>了。同时也限制了存储引擎能维护多少索引，完全取决于内存容量。</p><p>针对这个问题可以考虑<strong>将索引信息维护到磁盘当中</strong>，牺牲一定的读写性能，节省内存空间。</p><p>对于go语言通过使用<a href="https://crates.io/crates/jammdb">boltdb</a>这个库，其实现了标准的B+树。在学习MySQL时了解InnoDB存储引擎下的数据结构是B+Tree，其是一个磁盘IO友好型的数据结构。在相同数据量下，树的高度更低，这意味着需要较少次数的IO。并且在叶子节点之间通过链表连接，可以实现双先遍历，支持范围查询。</p><blockquote><p>如果DB使用B+树索引，不会从数据文件中加载索引，那么对于WriteBatch有一定的影响，无法获取最新的事务序列号。</p><p>可以考虑加载数据文件获取最新序列号，或者直接禁用WriteBatch，或者数据库Close时候，最新的序列号记录到一个文件当中，启动时从文件中获取。</p><p>但是在数据库异常情况下没有正常Close，会导致序列号没有正常写入，因此实际中可以考虑禁用WriteBatch功能。</p></blockquote><h3 id="索引迭代器设计"><a href="#索引迭代器设计" class="headerlink" title="索引迭代器设计"></a>索引迭代器设计</h3><p>考虑到不同的索引结构，将索引迭代器设计成一个通用的接口，方便不同的索引接口实现迭代器。</p><pre class=" language-go"><code class="language-go"><span class="token keyword">type</span> Iterator <span class="token keyword">interface</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token function">Rewind</span><span class="token punctuation">(</span><span class="token punctuation">)</span>                   <span class="token comment" spellcheck="true">// 重新回到迭代器的起点</span>    <span class="token function">Seek</span><span class="token punctuation">(</span>key <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span><span class="token punctuation">)</span>           <span class="token comment" spellcheck="true">// 从索引结构中查找 key, 从这个位置开始遍历</span>    <span class="token function">Next</span><span class="token punctuation">(</span><span class="token punctuation">)</span>                     <span class="token comment" spellcheck="true">// 跳转下一个Key</span>    <span class="token function">Valid</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token builtin">bool</span>               <span class="token comment" spellcheck="true">// 是否有效，即是否已经遍历完了所有的 key，用于退出遍历</span>    <span class="token function">Key</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span>               <span class="token comment" spellcheck="true">// 获取当前 key</span>    <span class="token function">Value</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span>data<span class="token punctuation">.</span>LogRecordPos <span class="token comment" spellcheck="true">// 获取当前 key 对应的数据位置信息</span>    <span class="token function">Close</span><span class="token punctuation">(</span><span class="token punctuation">)</span>                    <span class="token comment" spellcheck="true">// 关闭迭代器</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><p>对于B树来说，通过将当前的所有值拷贝到一个value数组中，通过遍历下标方式获取指定的值。</p><h3 id="索引锁粒度优化"><a href="#索引锁粒度优化" class="headerlink" title="索引锁粒度优化"></a>索引锁粒度优化</h3><p>在之前的设计中，内存中只有一个索引的结构，所有的写入和读取都会竞争这个索引数据结构的锁，在高并发的场景下，这可能会是一个性能瓶颈。</p><p>我们可以将这个锁的粒度减小，使用多个索引结构，然后将 key 通过 hash 取模映射到不同的索引数据结构中。</p><p>这样一来，只有映射到相同索引之中的 key 才会竞争同一把锁，这避免了去维护一个全局索引锁，大大减少了锁的粒度，并发性能能够得到提升。</p><h2 id="数据清理"><a href="#数据清理" class="headerlink" title="数据清理"></a>数据清理</h2><p>在这之前我们提到了，数据写入和删除都是写入一条数据记录，当删除一条记录时写入一条墓碑记录到数据文件，再更新内存索引，在这之前的记录也就无效了；在使用watchbatch批量写入时，当写入中途失败时（数据库崩溃），导致记录无效，这些无效数据会占用一定的无效空间。</p><p>因此在Bitcask论文中，考虑通过merge操作，将有效的数据进行重写，同时可以生成针对有效数据的索引信息，在启动数据库时直接加载，而不需要重复构造，有利于在数据库崩溃时快速加载，采用和写入数据文件一样的方式，不过存储的value信息，是key所在的磁盘位置信息，Fid，Offset，Size信息。</p><p>为了避免进行merge操作时，导致正常业务的阻塞，通过将数据文件拷贝到另一个文件夹中，进行操作，不影响业务正常的运行：</p><ul><li>当前活跃文件转为olderFile，并打开新的文件作为activeFile写入</li><li>将olderFile直接拷贝到其他文件夹中（merge后缀标记）</li><li>注意检查当前磁盘空间是否够完成merge操作，是否达到merge的上限阈值</li><li>完成文件拷贝后，可以释放锁，此时备份库和正在运行的库不存在冲突问题</li><li>新建一个Bitcask实例，以及一个Hint文件存放有效记录的索引信息</li><li>读取mergeFile每一条记录，对比索引内的信息，如果一致说明有效，清除事务标记，写入到Hint文件中</li><li>持久化后，写表示mergeFinishFile的文件，并且写入未完成merge的文件id</li></ul><h2 id="数据读写操作"><a href="#数据读写操作" class="headerlink" title="数据读写操作"></a>数据读写操作</h2><h3 id="数据记录的格式"><a href="#数据记录的格式" class="headerlink" title="数据记录的格式"></a>数据记录的格式</h3><p><img src="/../images/bitcask-5.png" alt="86fa8ea438b97ab9e369852c9b409555e34e23cdc0ef4978004a9a65918ab710"></p><p>一条数据记录主要包括了以下几个字段：</p><ul><li><p>CRC占用4个字节，用于校验记录的有效性</p></li><li><p>Type占用1个字节，用来表示记录的类型</p></li><li><p>KeySize、ValueSize使用变长（最大5个字节），表示后面Key和Value的长度</p></li><li><p>以上作为LogRecord的Header部分，Header是固定长度的，读取一条记录时先读取header部分，解析后多余的字节会忽略，反序列号后得到KeySize和ValueSize的信息</p></li><li><p>Key&#x2F;Value部分也是变长的</p></li></ul><blockquote><p>通过将字段设计为变长，节省了存储空间。如果keysize是u32类型，不使用变长，将固定占据4字节，有的时候key长度很小，例如长度为5，只需要1个字节存储。</p></blockquote><h3 id="写入记录"><a href="#写入记录" class="headerlink" title="写入记录"></a>写入记录</h3><p>在写入一条记录之前，对Key进一步编码，在前缀增加一个Seq，表示是普通记录，还是事务记录。在merge完成时会去除事务序列号。加载到内存中时加载时realKey。</p><ul><li>使用1个字节存储Type</li><li>然后使用变长字段记录KeySize和ValueSize</li><li>将编码后的header拷贝到数组当中，然后拷贝key和value</li><li>最后做一个crc校验，插入到头部</li></ul><p>写入一条记录时先写入Type，计算Key，Value的大小写入，再写入Key，Value，最后做一个CRC校验，写入记录的头部。</p><h3 id="读取记录"><a href="#读取记录" class="headerlink" title="读取记录"></a>读取记录</h3><ul><li>拿到Header后，如果判断keySize和ValueSize均为0，则说明读取到了文件末尾，返回一个EOF错误</li><li>根据Offset + KeySize和ValueSize的总和，读取一个字节数组，包含了Key&#x2F;Value的信息</li><li>再根据crc以后的几个字段，计算出crc值，对比header中的crc值进行校验</li></ul><p>读取一条记录时，先读取头部信息，判断keySize和ValueSize是否有效，为0说明读取到了文件末尾，返回一个EOF错误；否则根据Header中的Size信息，读取Key和value信息；最后计算读取的header中除了crc字段，加上key，value计算得出的crc值，与记录中的crc值是否一直，避免记录被破坏。</p>]]></content>
      
      
      
        <tags>
            
            <tag> golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式场景 | 全局ID生成</title>
      <link href="/2023/09/12/6-%E5%88%86%E5%B8%83%E5%BC%8FID/"/>
      <url>/2023/09/12/6-%E5%88%86%E5%B8%83%E5%BC%8FID/</url>
      
        <content type="html"><![CDATA[<blockquote><p>参考文章</p><ul><li><a href="https://tech.meituan.com/2017/04/21/mt-leaf.html">Leaf——美团点评分布式ID生成系统</a></li><li><a href="https://javaguide.cn/distributed-system/distributed-id.html">JavaGuide</a></li><li><a href="https://pdai.tech/md/arch/arch-z-id.html">分布式系统-全局唯一ID实现方案</a></li></ul></blockquote><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在复杂分布式系统中，需要对大量的数据和消息进行<strong>唯一标识</strong>，比如美团点评的金融、支付、餐饮等产品系统，淘宝的订单号…</p><p>单纯的数据库自增ID无法满足需求：</p><ol><li>ID冲突问题：在跨数据中心的分布式系统中，由于网络延迟和其他因素，单纯的数据库自增ID很难确保全局唯一性。</li><li>单点故障：如果数据库出现问题或宕机，那么新的ID将无法生成，从而影响整个系统的可用性。</li><li>ID预测问题：因为自增ID是连续的，恶意用户可能会尝试预测下一个ID，从而可能进行某种形式的攻击或数据抓取。</li><li>迁移和备份问题：在数据迁移或备份恢复的过程中，自增ID可能会带来问题，因为原始的ID序列可能会被打破。</li><li>…</li></ol><p>一个好的ID生成系统应该满足什么：</p><ul><li>全局唯一性</li><li>趋势递增</li><li>单调递增</li><li>信息安全</li></ul><blockquote><p>常用的性能评价指标：</p><ul><li>QPS：每秒钟处理的查询或请求数量。</li><li>TPS：每秒钟处理的事务数量。事务的定义可以根据上下文而变，但通常指的是一个完整的操作，例如从数据库中读取或写入数据。</li><li>RT：系统响应请求所需的时间。</li><li>Latency：数据从源点到目的地的传输时间。</li></ul></blockquote><h2 id="UUID"><a href="#UUID" class="headerlink" title="UUID"></a>UUID</h2><p>UUID(Universally Unique Identifier)的标准型式包含32个16进制数字，以连字号分为五段，形式为8-4-4-4-12的36个字符，示例：<code>550e8400-e29b-41d4-a716-446655440000</code>。</p><p>存在几种不同版本的UUID，每个版本都有自己的生成方法。最常用的版本是v1（基于时间和机器的MAC地址）和v4（基于随机数）</p><p>优点：性能高，基于本地生成，没有网络传输消耗。</p><p>缺点：</p><ul><li>过长不易于存储：UUID本身包含32个16进制数，算上4个连字符，二进制下需要（32 + 4 ） * 4 &#x3D; 144位。</li><li>信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露。</li><li>不适合作为DB主键，在特定场景下存在问题<ul><li>MySQL官方有明确的建议主键要尽量越短越好</li><li>作为主键时，有序性能够保证数据在物理上的顺序，提高数据的读取效率；在InnoDB的B+树索引下，支持主键的有序性能够保证范围查询的效率；每次插入新数据时，都是插入到主键索引的最后一个位置，这样就避免了数据移动和索引重建的开销</li></ul></li></ul><h2 id="雪花算法"><a href="#雪花算法" class="headerlink" title="雪花算法"></a>雪花算法</h2><h3 id="1-组成"><a href="#1-组成" class="headerlink" title="1. 组成"></a>1. 组成</h3><p>雪花算法是由Twitter开源的分布式ID生成算法，以划分命名空间的方式将 64-bit位分割成多个部分，每个部分代表不同的含义。</p><p><img src="/../images/1460000040964520.png" alt="img"></p><ul><li>1位是符号位，也就是最高位，始终是0，没有任何意义，因为要是唯一计算机二进制补码中就是负数，0才是正数。</li><li>41位是时间戳，具体到毫秒，41位的二进制可以使用69年，因为时间理论上永恒递增，所以根据这个排序是可以的。</li><li>10位是机器标识，10位最多可以表示1024台机器，雪花算法的Id唯一性主要靠机器码保证。<ul><li>如果对IDatacenter（互联网数据中心）有需求，还可以将 10-bit 分 5-bit 给 IDC，分5-bit给工作机器workerId，worker可以是进程、线程、协程等。</li><li>在多个数据中心中使用相同的机器编号，由于 IDC 标识符的不同，也不会出现冲突。</li><li><strong>可以采用本机IPv4地址最后两段以及进程Id一起作为机器码</strong>，确保机房内部不同机器，以及相同机器上的不同进程，拥有不同的机器码。</li><li>如果要保证绝对不相同的机器码，可以通过手动设置唯一的workerID方式来实现。</li></ul></li><li>12-bit位是自增序列，可表示2^12 &#x3D; 4096个数。</li></ul><h3 id="2-优缺点"><a href="#2-优缺点" class="headerlink" title="2. 优缺点"></a>2. 优缺点</h3><p>优点：</p><ul><li>毫秒数在高位，自增序列在低位，整个ID都是趋势递增的，后续插入数据库的索引树的时候，性能较高。</li><li>生成ID时不依赖于数据库，完全在内存生成，高性能高可用。</li><li>可以根据自身业务特性分配bit位，非常灵活。</li></ul><p>缺点：</p><ul><li>强依赖机器时钟一致性，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。<ul><li>回拨时间小的时候，不生成 ID，循环等待到时间点到达。</li><li>回拨时间过长，利用拓展位，回拨之后在拓展位上加1就可以了，这样ID依然可以保持唯一。但是这个要求我们提前预留出位数，要么从机器id中，要么从序列号中，腾出一定的位，在时间回拨的时候，这个位置 <code>+1</code>。</li><li>美团针对这个提出了Leaf方案，UidGenerator是百度开源的分布式ID生成器，其基于雪花算法实现。</li></ul></li><li>在当第三部分的机器的数量超过机房的个数限制了，导致机器码重复，同一毫秒内，两个使用相同机器ID和数据中心ID的机器可能会产生完全相同的ID，尤其是如果它们的序列号也相同。</li></ul><h3 id="3-相关问题"><a href="#3-相关问题" class="headerlink" title="3. 相关问题"></a>3. 相关问题</h3><ol><li><p>workId 怎么保证唯一？机器号是预先分配的，那实际中机器上下线情况，这个机器开始抢占了一个，后来下线了，新上来的机器如何分配</p><ul><li><p>可以通过分布式缓存来保存机器ID和workId之间的映射关系。启动的时候访问分布式缓存查询当前机器ID对应的workId，如果查询不到则获取一个并保存到分布式缓存中。</p></li><li><p>可通过Zookeeper管理workId，免去手动频繁修改集群节点，去配置机器ID的麻烦。当新机器上线时，它可以从ZooKeeper请求一个机器号；当机器下线时，这个号可以被回收并在未来重新分配</p></li><li><p>如果采用静态配置方案，每个机器号都是预先分配的，即使机器下线，机器号也不会重新分配，新机器加入只能手动分配。</p></li></ul></li><li><p>雪花算法1s之内最多可以生成多少个不同的ID</p><ul><li>12-bit位是序列号，可以标识2^12&#x3D;4096</li><li>但考虑到1秒有1000毫秒，所以一个节点在1秒内最多可以生成：4096×1000&#x3D;4,096,000</li><li>考虑到10位机器标识允许多达1024个节点，所以如果每个节点都达到最大生成能力，那么系统在1秒内总共可以生成：4,096,000×1024&#x3D;4,194,304,000，越41亿</li><li>在10位机器全用于标识机器，全负载情况下，约能生成越41亿ID</li></ul></li><li><p>随机数避免一个机器上面单秒之内的订单冲突，限制是多少，支持多少位</p><ul><li>标准的雪花算法如上，单个节点单毫秒内超过4096个部分，必须等到下一毫秒</li></ul></li></ol><h2 id="MySQL实现"><a href="#MySQL实现" class="headerlink" title="MySQL实现"></a>MySQL实现</h2><p>MySQL通过参数<code>auto_increment_increment</code>和<code>auto_increment_offset</code>，设置主键（自增列）开始的ID值和每次递增的偏移值参数。</p><p>优点：</p><ul><li>非常简单，利用现有数据库系统的功能实现，成本小，有DBA专业维护。</li><li>ID号单调自增，可以实现一些对ID有特殊要求的业务。</li></ul><p>缺点：</p><ul><li>强依赖DB，当DB异常时整个系统不可用，属于致命问题。通过配置主从复制可以尽可能的增加可用性，但是数据一致性在特殊情况下难以保证，主从切换时的不一致可能会导致重复发号。</li><li>ID发号性能瓶颈限制在单台MySQL的读写性能。</li></ul><p>为了解决MySQL的性能问题，提出如下的解决办法：通过部署多台机器，每台机器设置不同的初始值，且步长和机器数相等。保证每台机器之间生成不同的Id。</p><p>但是这又带来相应问题问题：<strong>水平扩展比较困难</strong>，前面提到步长和机器数相等，在初期已经定好步长和机器数后，添加机器要麻烦的多。需要先将扩展的机器设置在之前机器生成的ID范围之后，保证生成id唯一性，然后调整之前的机器到定义的号码段，当机器数量大时，扩容十分困难。</p><p>同时<strong>ID没有了单调递增</strong>的特性，只能趋势增加，每次获取ID读写数据库，数据库压力大时，只能靠堆机器来提高性能。</p><h2 id="Redis实现"><a href="#Redis实现" class="headerlink" title="Redis实现"></a>Redis实现</h2><p>Redis实现分布式唯一ID主要是通过提供像 <code>INCR</code> 和 <code>INCRBY</code> 这样的自增原子命令，由于Redis自身的单线程的特点所以能保证生成的 ID 肯定是唯一有序的。</p><pre class=" language-shell"><code class="language-shell">127.0.0.1:6379> set sequence_id_biz_type 1OK127.0.0.1:6379> incr sequence_id_biz_type(integer) 2127.0.0.1:6379> get sequence_id_biz_type"2"</code></pre><p>当采用集群方式获取高吞吐量时，像MySQL方式一样，设置每台Redis值不同的初始值和偏移值，当时引入的成本极大。</p><p>同时Redis是基于内存的，需要持久化数据，避免重启机器或者机器故障后数据丢失。Redis主要通过AOF和RDB实现持久化。</p><p>优点：性能高，生成的数据有序递增</p><p>缺点：引入Redis，增加系统的复杂度</p><ul><li>依赖于redis，需要系统引进redis，增加了系统的复杂性</li><li>在单机上是递增的，但是由于涉及到分布式环境，每台机器上的时钟不可能完全同步，有时候会出现不时全局递增的情况</li></ul><h2 id="Leaf算法"><a href="#Leaf算法" class="headerlink" title="Leaf算法"></a>Leaf算法</h2><h3 id="Leaf-segment"><a href="#Leaf-segment" class="headerlink" title="Leaf-segment"></a>Leaf-segment</h3><p>美团在数据库生成的方案上，提出了改进，通过批量获取ID值，避免每次获取ID都读写数据库，造成数据库压力过大。</p><ul><li>通过维护一张表，记录不同业务的发号需求，保证每个biz-tag的ID获取相互隔离，互补影响</li><li>每次根据业务中的step，获取一个segment的号段的值，用完再去数据库获取新的号段</li><li>当后续业务因为性能对数据库扩容时，只需要对biz_tag分库分表即可</li></ul><p>优点：</p><ul><li>Leaf服务可以很方便的<strong>线性扩展</strong>，性能完全能够支撑大多数业务场景</li><li>ID号码是趋势递增的8byte的64位数字，满足上述数据库存储的主键要求</li><li>容灾性高：Leaf服务内部有号段缓存，即使DB宕机，短时间内Leaf仍能正常对外提供服务</li><li>可以自定义max_id（表示该业务当前被分配的ID号段的最大值）的大小，非常方便业务从原有的ID方式上迁移过来</li></ul><p>缺点：</p><ul><li>ID号码不够随机，能够泄露发号数量的信息，不太安全。</li><li>TP999数据波动大，当号段使用完之后还是会hang在更新数据库的I&#x2F;O上，tg999数据会出现偶尔的尖刺。</li><li>DB宕机会造成整个系统不可用。</li></ul><h3 id="双buffer优化"><a href="#双buffer优化" class="headerlink" title="双buffer优化"></a>双buffer优化</h3><p>前面叙述的Leaf-segment，在号段消耗完后进行取号，在这个过程中由于网络抖动、慢查询造成号段没有取到或者延迟，造成线程阻塞（无法分配新的主键ID）。</p><p>采用双buffer，在Leaf服务内部用两个号段缓存区segment，当一个号段消费10%时，去另起线程更新下一个号段，当前号段全部消费完时，如果下一个segment准备好了，就直接切换过去，循环反复。</p><ul><li>将segment设置为服务高峰期发号QPS的600倍，即使DB宕机，也能保证一段时间内的持续发号，业务不受影响</li></ul><blockquote><p>我理解这里两端segment是缓存在数据库之外的。</p></blockquote><ul><li>每次请求来临，会判断下一个号段的状态，从而更新此号段，偶尔的网络抖动不会影响下个号段的更新</li></ul><h3 id="Leaf-snowflake"><a href="#Leaf-snowflake" class="headerlink" title="Leaf-snowflake"></a>Leaf-snowflake</h3><p>Leaf-segment生成的ID是可以计算的，不适合订单生成场景，容易被竞对计算出销量，泄露信息。</p><p>接着美团提出了Leaf-snowflake方案，沿用snowflake方案的bit设计。</p><p>相比传统雪花算法，采用Zookeeper持久顺序节点的特性，自动对snowflake节点配置workerID：</p><ol><li>启动Leaf-snowflake服务，连接Zookeeper，在leaf_forever父节点下检查自己是否已经注册过（是否有该顺序子节点）。</li><li>如果有注册过直接取回自己的workerID（zk顺序节点生成的int类型ID号），启动服务。</li><li>如果没有注册过，就在该父节点下面创建一个持久顺序节点，创建成功后取回顺序号当做自己的workerID号，启动服务。</li></ol><h3 id="弱依赖ZooKeeper"><a href="#弱依赖ZooKeeper" class="headerlink" title="弱依赖ZooKeeper"></a>弱依赖ZooKeeper</h3><p>每次去ZK获取数据后，也会在本机文件系统上缓存一个workerID文件，当ZK出现问题，恰好问题出现问题需要重启时，能保证服务正常启动，减少对ZK的依赖。</p><h3 id="解决时钟问题"><a href="#解决时钟问题" class="headerlink" title="解决时钟问题"></a>解决时钟问题</h3><p>雪花算法对于时钟具有依赖性，如果机器的时钟发生了回拨，可能会生成重复的ID号，需要解决<strong>时钟回退</strong>的问题。</p><ul><li>首先通过ZK检查是否写过节点</li><li>如果写过，通过当前的自身系统时间与之前的周期性上传的时间对比，如果小于说明发生了大步长回拨，服务启动失败并报警</li><li>如果没有写过说明是一个新服务节点，直接创建持久节点，写入自身系统时间。</li><li>接着对比其他Leaf节点的系统时间，来判断自身系统时间是否正确，获取到所有临时节点的系统的系统时间，计算出平均时间，如果系统时间与平均值的差值小于阈值，说明是正常的，否则认为发生了大步长偏移，启动失败报警</li><li>每隔一段时间(3s)上报自身系统时间写入leaf_forever</li></ul><blockquote><p>ZK中包含了leaf_forever和leaf_temporary的两种节点。</p><ul><li>leaf_forever是ZK创建的普通节点，不会受到客户端会话的影响，除非主动删除或者ZK集群崩溃，节点一直存在。这些节点通常用于存储持久性的配置信息、元数据或其他长期存在的数据。</li><li>leaf_temporary是临时节点，其生命周期与创建该节点的客户端会话相关联。如果会话结束（比如客户端崩溃或关闭连接），临时节点会被自动删除。这些节点通常用于表示短期状态、临时任务或服务实例的存在。比如，服务实例启动时可以创建临时节点，退出时会自动删除该节点。</li></ul></blockquote><p>美团也提出由于雪花算法对时钟强依赖性，对时间的要求比较敏感，在机器工作时NTP同步（计算机网络时间同步）也会造成秒级别的回退，建议可以直接关闭NTP同步。要么在时钟回拨的时候直接不提供服务直接返回ERROR_CODE，等时钟追上即可。<strong>或者做一层重试，然后上报报警系统，更或者是发现有时钟回拨之后自动摘除本身节点并报警</strong>。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>UUID：</p><ul><li>通过机器网卡、当地时间、随机数方式生成，本地生成。可以通过当前的时间戳及机器 mac 地址来生成，可以确保生成的 UUID 全球唯一</li><li>生成的位数多，不易于存储</li><li>生成的ID是无序字符串，查询效率低下，没有实际业务含义</li></ul><p>雪花算法：</p><ul><li>对于时钟具有强依赖性，有时间回拨缺点。</li><li>可以通过其他为划分，当发生时间回拨时，启动额外的位，避免ID重复</li><li>对于小尺度，可以通过等待时间正常</li><li>或者是抛出异常，退出</li></ul><p>MySQL生成：</p><ul><li>每次都需要读写数据库，性能差</li><li>通过多机部署方式，设置不同的初始值和偏移量，但是水平难以扩展</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WSL中配置golang环境</title>
      <link href="/2023/09/03/1-wsl+golang/"/>
      <url>/2023/09/03/1-wsl+golang/</url>
      
        <content type="html"><![CDATA[<h2 id="配置WSL"><a href="#配置WSL" class="headerlink" title="配置WSL"></a>配置WSL</h2><blockquote><p>参考文章：<a href="https://deepinout.com/wsl-tutorials/wsl-install-and-quick-start.html">WSL安装</a></p></blockquote><h3 id="切换root用户"><a href="#切换root用户" class="headerlink" title="切换root用户"></a>切换root用户</h3><pre class=" language-shell"><code class="language-shell">sudo passwd rootsu</code></pre><h3 id="限制Vmmem内存"><a href="#限制Vmmem内存" class="headerlink" title="限制Vmmem内存"></a>限制Vmmem内存</h3><ol><li><p>按下<code>Windows + R</code>键，输入<code>%UserProfile%</code>并运行进入用户文件夹</p></li><li><p>新建文件<code>.wslconfig</code>，然后记事本编辑</p></li><li><p>填入以下内容并保存, memory为系统内存上限，这里我限制最大2GB，可根据自身电脑配置设置</p></li></ol><pre class=" language-shell"><code class="language-shell">[wsl2]memory=4GBswap=8GBlocalhostForwarding=true</code></pre><ol start="4"><li>输入<code>wsl --shutdown</code>来关闭当前的子系统，重启wsl</li></ol><h3 id="使用docker"><a href="#使用docker" class="headerlink" title="使用docker"></a>使用docker</h3><pre class=" language-shell"><code class="language-shell"> curl -fsSL https://test.docker.com -o test-docker.sh sudo sh test-docker.sh  # 验证docker是否安装成功 systemctl status docker</code></pre><pre class=" language-shell"><code class="language-shell"># 启动dockersystemctl start docker# 查看当前的容器docker ps -a# 启动容器docker  start 容器名或者容器id# 停止容器docker  stop 容器名或容器id# 强制关闭容器docker container kill 容器名或容器id# 或可简写为docker kill 容器名或容器id</code></pre><pre class=" language-shell"><code class="language-shell">docker psdocker exec -it d498d9f00612 /bin/bashselect  host, user, authentication_string, plugin from mysql.user;use mysqlupdate user set host = '%' where user = 'root';alter user 'root'@'%' identified with mysql_native_password by 'shixiaocaia';FLUSH PRIVILEGES;</code></pre><h3 id="配置Git"><a href="#配置Git" class="headerlink" title="配置Git"></a>配置Git</h3><pre class=" language-shell"><code class="language-shell">sudo apt updatesudo apt install gitgit --versiongit version 1.8.1.2</code></pre><pre class=" language-shell"><code class="language-shell"># 配置用户信息git config --global user.name "shixiaocaia"​git config --global user.email shixiaocaia@gmail.com​git config --list# 配置SSHssh-keygen -t rsa -C "这里换上你的邮箱"# 不需要密码，直接三次回车# 生成id_rsa和id_rsa.pub# 添加公钥pub文件内容，到Settings -- SSH and GPG keys​cat ~/.ssh/id_rsa.pub# 测试配置成功ssh -T git@github.com</code></pre><h3 id="启动目录"><a href="#启动目录" class="headerlink" title="启动目录"></a>启动目录</h3><ul><li>打开中终端设置，搜索wsl</li></ul><pre class=" language-shell"><code class="language-shell">&#123;    "guid": "&#123;72130475-4d4b-5774-bc1a-2a09ff7f0056&#125;",    "hidden": false,    "name": "Ubuntu2204",    "source": "Windows.Terminal.Wsl",    "startingDirectory": "//wsl$/Ubuntu2204/home/xiaocai"&#125;</code></pre><ul><li>如果是其他终端工具，设置工作目录<code>//wsl$/Ubuntu2204/home/xiaocai</code></li></ul><h2 id="自动安装"><a href="#自动安装" class="headerlink" title="自动安装"></a>自动安装</h2><pre class=" language-shell"><code class="language-shell">sudo apt install golang-goapt remove golang-go</code></pre><p>用这样的办法自动安装的golang并非最新版</p><h2 id="手动安装"><a href="#手动安装" class="headerlink" title="手动安装"></a>手动安装</h2><ol><li>查看<a href="https://golang.google.cn/dl/">google发布的golang版本</a>，选择合适的版本安装。</li></ol><pre class=" language-shell"><code class="language-shell">wget https://studygolang.com/dl/golang/go1.20.5.linux-amd64.tar.gz</code></pre><ol start="2"><li>解压到<code>/usr/local</code></li></ol><pre class=" language-shell"><code class="language-shell">tar -C /usr/local -xzf go1.20.5.linux-amd64.tar.gz</code></pre><ol start="3"><li>设置环境变量</li></ol><pre class=" language-shell"><code class="language-shell">vim /etc/profile</code></pre><pre class=" language-shell"><code class="language-shell">export GOPATH=/home/xiaocai/goexport GOROOT=/usr/local/goexport PATH=$PATH:$GOROOT/bin:$GOPATH/bin</code></pre><pre class=" language-shell"><code class="language-shell">source /etc/profile</code></pre><ol start="4"><li>其他设置</li></ol><pre class=" language-shell"><code class="language-shell"># 配置代理go env  -w GOPROXY=https://goproxy.cn,https://goproxy.io,direct# Go Moudlego env -w GO111MODULE=on</code></pre><ol start="5"><li>查看环境是否安装成功</li></ol><pre class=" language-shell"><code class="language-shell">go envgo version</code></pre><h2 id="golang配置"><a href="#golang配置" class="headerlink" title="golang配置"></a>golang配置</h2><p><img src="/../images/go1.png" alt="20230907102715106"></p><ul><li><p>添加语言运行时</p></li><li><p>使用<code>whereis go</code>，得到<code>go: /usr/local/go /usr/local/go/bin/go /mnt/d/Go/bin/go.exe</code></p><ul><li><p>第一个参数是go sdk文件夹</p></li><li><p>第二个参数<code>/usr/local/go/bin/go</code>对应Go可执行文件参数</p></li><li><p>第三个是Windows10里面的go环境映射到了wsl2</p></li></ul></li></ul><p><img src="/../images/go2.png" alt="20230907102932244"></p><ul><li>运行&#x2F;调试配置更改</li></ul><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h3 id="127-0-0-1"><a href="#127-0-0-1" class="headerlink" title="127.0.0.1"></a>127.0.0.1</h3><p><a href="https://learn.microsoft.com/zh-cn/windows/wsl/networking">官方文档说明</a></p><ul><li>wsl下的<code>127.0.0.1</code>并不能正确访问，应该使用<code>localhost</code>进行访问，得到一种解释：<code>127.0.0.1</code>要走从网络层全链路走一圈的，<code>localhost</code>则不必。</li><li>wsl访问windows下的服务，需要通过IP地址方式，<code>ip route | grep default | awk &#39;&#123;print $3&#125;&#39;</code>获取本机IP地址。</li></ul><h3 id="wsl备份以及恢复"><a href="#wsl备份以及恢复" class="headerlink" title="wsl备份以及恢复"></a>wsl备份以及恢复</h3><pre class=" language-shell"><code class="language-shell">wsl -l -v # 确认wsl版本# 提前创建文件夹wsl --export Ubuntu2204 D:\wsl\ubuntu.tar # 导出Ubuntu2204 到d盘wsl --unregister Ubuntu2204 # 注销旧版本wsl -l -v # 确认注销wsl --import Ubuntu2204 D:\wsl D:\wsl\ubuntu.tar # 导入备份文件wsl -s Ubuntu2204 # 设置为默认</code></pre><p>还原后的子系统进入后，默认成了 root 用户，解决方法如下，在终端启动时，配置<code>wsl.exe -d Ubuntu2204 -u xiaocai</code>。</p><h3 id="docker-desktop"><a href="#docker-desktop" class="headerlink" title="docker-desktop"></a>docker-desktop</h3><ul><li>默认情况下，Docker Desktop for Window会创建如下两个发行版（distro）：<ul><li>docker-desktop：用于存放程序</li><li>docker-desktop-data：用于存放镜像</li></ul></li><li>docker-desktop-data部分应该按照5.2一样正常迁移</li></ul><pre class=" language-shell"><code class="language-shell">wsl --export docker-desktop-data D:\wsl\docker-data.tarwsl --unregister docker-desktop-datawsl --import docker-desktop-data D:\wsl\docker D:\wsl\docker-data.tarwsl -l -v</code></pre><h3 id="goland-error-obtaining-VCS-status-exit-status-128"><a href="#goland-error-obtaining-VCS-status-exit-status-128" class="headerlink" title="goland error obtaining VCS status: exit status 128"></a>goland error obtaining VCS status: exit status 128</h3><p>设置，<code>go env -w GOFLAGS=&quot;-buildvcs=false&quot;</code></p><h3 id="fatal-detected-dubious-ownership-in-repository-at"><a href="#fatal-detected-dubious-ownership-in-repository-at" class="headerlink" title="fatal: detected dubious ownership in repository at"></a>fatal: detected dubious ownership in repository at</h3><ul><li>启动用户更换成了root，导致goland打开项目时也是root，和创建文件的xiaocai不一致</li><li>修改&#x2F;etc&#x2F;wsl.conf，设置默认启动用户</li></ul><pre class=" language-shell"><code class="language-shell">[boot]systemd=true[user]default = xiaocai</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang | GMP模型</title>
      <link href="/2023/07/12/4-GMP%E6%A8%A1%E5%9E%8B/"/>
      <url>/2023/07/12/4-GMP%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<blockquote><p>参考资料</p><ol><li><a href="https://mp.weixin.qq.com/s/jIWe3nMP6yiuXeBQgmePDg">小徐先生的编程世界——Golang GMP 原理</a></li><li><a href="https://learnku.com/articles/41728">刘丹冰博客</a></li></ol></blockquote><h2 id="进程、线程、协程"><a href="#进程、线程、协程" class="headerlink" title="进程、线程、协程"></a>进程、线程、协程</h2><h3 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h3><p>进程是运行起来的可执行程序，运行一个程序会创建一个或者多个进程；</p><ul><li>创建进程，需要分配栈区、文件映射区等空间，所以说进程是资源分配的最小单位；</li><li>每个进程有自己的独立地址空间，不与其他进程分享，但是进程间的线程彼此共享同一个虚拟地址空间；</li><li>如果需要实现进程通信方式，需要使用管道、共享内存、信号量、信号等机制。</li></ul><h3 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h3><p>通常语义下，指的是内核级的线程。</p><ul><li><p>是操作系统调度的基本单位；</p></li><li><p>创建、销毁、调度由内核完成，cpu需要在内核态和用户态之间切换；</p></li><li><p>同一个进程下的线程共享内核空间的资源；</p></li><li><p>可充分利用多核、实现并行。</p></li></ul><h3 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h3><p>协程（coroutine）是线程的子集，是用户态线程。</p><ul><li>与线程存在映射关系，将线程资源进一步划分，看成M：1关系；</li><li>创建、销毁、调度由用户态完成，对内核透明；</li><li>从属于同一个内核级线程，无法并行。一个协程阻塞会导致从属同一个线程的所有协程无法执行；<ul><li>发生阻塞时，对于操作系统来说看成是一个线程发生阻塞，无法察觉是一个协程阻塞</li></ul></li></ul><p>协程与线程的区别：</p><ul><li>协程相比线程来说更小，只有2k大小，可以允许更多的协程来实现高并发</li><li>协程的上下文切换不需要经过用户态到内核态的转换，且保存的寄存器值更少，上下文切换成本小，效率高</li><li>通过语言层面的内置协程调度器，利用多个线程实现了协程并行</li></ul><h2 id="Goroutine"><a href="#Goroutine" class="headerlink" title="Goroutine"></a>Goroutine</h2><p>goroutine是从普通的coroutine演变过来的，做了如下优化：</p><ul><li>通过在中间增加了调度器，实现协程与线程存在映射关系，为 M：N；</li><li>通过设置多个调度器利用多个线程，实现协程并行；</li><li>通过调度器的斡旋，实现和线程间的动态绑定和灵活调度；</li><li>栈空间大小可动态扩缩，因地制宜。</li></ul><h2 id="GMP模型"><a href="#GMP模型" class="headerlink" title="GMP模型"></a>GMP模型</h2><p>GMP 是go语言协程调度模型，其由协程 goroutine + 内核线程 machine + 逻辑处理器 processor 构成，通过调度器P将可执行的协程 G 放到对应的工作线程 M 上调度执行。</p><p><img src="/../images/gmp-1.png" alt="f0499e91-cfd4-4626-bce4-f10550651190"></p><h3 id="具体构成"><a href="#具体构成" class="headerlink" title="具体构成"></a>具体构成</h3><ul><li><p>g &#x3D; goroutine，是 golang 对协程的抽象</p><ul><li>g 有自己的运行栈、状态、以及执行的任务函数（用户通过 go func 指定）</li><li>g 需要绑定到 p 才能执行，在 g 的视角中，p 就是它的 cpu</li></ul></li><li><p>p &#x3D; processor，是 golang 中的调度器</p><ul><li>对 g 而言，p 是其 cpu，g 只有被 p 调度，才得以执行</li><li>对 m 而言，p 是其执行代理，为其提供必要信息的同时（可执行的 g、内存分配情况等），并隐藏了繁杂的调度细节</li><li>p 的数量决定了 g 最大并行数量，通过 GOMAXPROCS 进行设定（超过 CPU 核数时无意义），任意时刻都只有 $GOMAXPROCS 个 goroutine 在同时运行</li></ul></li><li><p>m &#x3D;  machine，是 golang 中对线程的抽象</p><ul><li>m 不直接执行 g，而是先和 p 绑定，由其实现代理</li><li>借由 p 的存在，m 无需和 g 绑死，也无需记录 g 的状态信息，因此 g 在全生命周期中可以实现跨 m 执行</li><li>go程序启动时，会设置 M 的最大数量，默认 10000。 但是内核很难支持这么多的线程数，所以这个限制可以忽略</li><li>当一个m发生阻塞，去寻找空闲的 M，如果没有会创建新的 m，去接管之前的P，避免阻塞m中的其他阻塞</li></ul></li><li><p>全局队列：存放等待运行的 G，本地存放不下的G会放到这里</p></li><li><p>P 的本地队列：同全局队列类似，存放的也是等待运行的 G，存的数量有限，不超过 256 个。新建 G’时，G’优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列</p></li><li><p>P 列表：所有的 P 都在程序启动时创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个</p></li><li><p>g0：是特殊的调度协程，不执行用户函数，负责执行 g 之间的切换调度，每个M有一个对应的g0</p></li></ul><h3 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h3><ul><li>M调度G前需要和P绑定，优先取P本地队列，其次取全局队列，最后取wait队列（为io阻塞就绪态goroutine队列）；这样的好处是，优先取本地队列时，可以接近于无锁化，减少全局锁竞争。</li><li>为防止不同P的闲忙差异过大，设立work-stealing机制，本地队列为空的P可以尝试从其他P本地队列偷取一半的G补充到自身队列，实现负载均衡。<ul><li>由于存在窃取情况，所以本地队列中还是需要考虑加锁，但是相比全局队列所有P都可能访问，发生概率很低，接近无锁化情况</li><li>全局队列当中，所有P都可能访问，所以需要加锁避免并发问题</li></ul></li></ul><h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><p>g的数据结构如下：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">type</span> g <span class="token keyword">struct</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// ...</span>    m         <span class="token operator">*</span>m          <span class="token comment" spellcheck="true">// ...</span>    sched     gobuf    <span class="token comment" spellcheck="true">// ...</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><p>m对应后续绑定的执行线程，可以进行动态调整</p><p><img src="/../images/gmp-2.png" alt="图片"></p><p>整个goroutine生命周期包括如上几个状态：</p><ul><li>当goroutine创建时处于gidle，完成初始化后进入gdead状态</li><li>当g可以执行，等待调度进入grunnable状态</li><li>成功被调度，进入grunning，执行逻辑<ul><li>当代码逻辑涉及内核态操作，会进入gsyscall系统调用的状态，阻塞等待，完成后又进入grunnable可执行等待调度的状态</li><li>有时可能涉及并发未获取到锁，进入gwaiting阻塞等待</li></ul></li><li>g成功调度执行完，进入gdead状态</li></ul><p>m的数据结构如下：</p><pre class=" language-c"><code class="language-c">type m <span class="token keyword">struct</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    g0      <span class="token operator">*</span>g     <span class="token comment" spellcheck="true">// goroutine with scheduling stack</span>    <span class="token comment" spellcheck="true">// ...</span>    tls           <span class="token punctuation">[</span>tlsSlots<span class="token punctuation">]</span>uintptr <span class="token comment" spellcheck="true">// thread-local storage (for x86 extern register)</span>    <span class="token comment" spellcheck="true">// ...</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><ul><li>对于一个m，包含了特殊的调度协程go，不用于执行用户函数，负责执行 g 之间的切换调度， 与 m 的关系为 1:1</li><li>tls：thread-local storage，线程本地存储，存储内容只对当前线程可见。 线程本地存储的是 m.tls 的地址，m.tls[0] 存储的是当前运行的 g，因此线程可以通过 g 找到当前的 m、p、g0 等信息</li></ul><p>p的数据结构如下：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">type</span> p <span class="token keyword">struct</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// ...</span>    runqhead <span class="token builtin">uint32</span>    runqtail <span class="token builtin">uint32</span>    runq     <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">]</span>guintptr        runnext guintptr    <span class="token comment" spellcheck="true">// ...</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><ul><li>runq对应一个P的本地队列，是一个双向队列</li><li>runqhead：队列头部</li><li>runqtail：队列尾部</li><li>runnext：下一个可执行的 goroutine</li></ul><pre class=" language-go"><code class="language-go"><span class="token keyword">type</span> schedt <span class="token keyword">struct</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// ...</span>    lock mutex    <span class="token comment" spellcheck="true">// ...</span>    runq     gQueue    runqsize <span class="token builtin">int32</span>    <span class="token comment" spellcheck="true">// ...</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><p>schedt 是全局 goroutine 队列的封装：</p><ul><li><p>lock：一把操作全局队列时使用的锁；</p></li><li><p>runq：全局 goroutine 队列；</p></li><li><p>runqsize：全局 goroutine 队列的容量.</p></li></ul><h2 id="调度流程"><a href="#调度流程" class="headerlink" title="调度流程"></a>调度流程</h2><h3 id="两种goroutine"><a href="#两种goroutine" class="headerlink" title="两种goroutine"></a>两种goroutine</h3><p>goroutine主要分为两类：</p><ul><li>负责调度普通 g 的 g0，执行固定的调度流程，与 m 的关系为一对一</li><li>负责执行用户函数的普通 g</li></ul><p>m 通过 p 调度执行的 goroutine 永远在普通 g 和 g0 之间进行切换，当 g0 找到可执行的 g 时，会调用 gogo 方法，调度 g 执行用户定义的任务；当 g 需要主动让渡或被动调度时，会触发 mcall 方法，将执行权重新交还给 g0。</p><h3 id="调度类型"><a href="#调度类型" class="headerlink" title="调度类型"></a>调度类型</h3><p><img src="/../images/gmp1.png" alt="图片"></p><ul><li>主动调度<ul><li>用户主动使用<code>Gosched</code>让出当前P的执行权，g投递到全局队列当中</li><li>此时g0重新获取到执行权，获取可执行的下一个g</li></ul></li><li>被动调度<ul><li>因当前不满足某种执行条件，g 可能会陷入阻塞态无法被调度，直到关注的条件达成后，g才从阻塞中被唤醒，重新进入可执行队列等待被调度。常见阻塞方式：加锁、有缓存的通道阻塞等待</li><li>当一个 g 需要进入被动调度状态，通过 gopark 陷入 gwaiting 状态，底层通过 mcall 将执行权归还给 g0</li><li>同时当前p和g进行解绑，g0获取下一个可以执行调度g</li><li>当g完成阻塞时，可以被唤醒时，通过某个p的g0调度到，将g尝试加入到主动唤醒操作（goready）的P本地队列当中</li></ul></li><li>正常调度<ul><li>g 中的执行任务已完成，g0 会将当前 g 置为死亡状态，发起新一轮调度</li></ul></li><li>抢占调度<ul><li>前面的操作，主要通过g0在用户态范围进行切换。抢占主要由一个全局监控者g完成，将某个执行系统调用时间过长的g与当前p进行解绑</li><li>某个 g 发起内核切换，由线程身份进入内核态发起系统调用，所以此时 m 由于系统调用陷入僵持态，此时对应 m 的 g0 无法得到执行，所以需要一个全局g来完成操作</li><li>全局 g 会把 P 抽离出去，尝试与其他m进行绑定执行，不影响之前的 m 和 g ，把 P 拿出去继续调度执行</li><li>这里发生抢占调度时机，主要判断当前是否为空闲状态，一般本地队列有需要执行的 g，或者没有空闲的 p 和 m 时，处于忙碌状态需要考虑抢占调度，也要看发生系统调用的时长是否过长</li></ul></li></ul><h3 id="宏观调度"><a href="#宏观调度" class="headerlink" title="宏观调度"></a>宏观调度</h3><p><img src="/../images/gmp2.png" alt="图片"></p><p>gmp一个从g0–&gt;g–&gt;过程，主要包含以下几个步骤：</p><ul><li>g0 执行 schedule() 函数，寻找到用于执行的 g</li><li>g0 执行 execute() 方法，更新当前 g、p 的状态信息，并调用 gogo() 方法，将执行权交给 g</li><li>g 因主动让渡( gosche_m() )、被动调度( park_m() )、正常结束( goexit0() )等原因，调用 m_call 函数，执行权重新回到 g0 手中</li><li>g0 执行 schedule() 函数，开启新一轮循环</li></ul><h3 id="findRunnable"><a href="#findRunnable" class="headerlink" title="findRunnable"></a>findRunnable</h3><p><img src="/../images/gmp3.png" alt="图片"></p><p>寻找可执行g进行调度额过程：</p><ul><li>为了避免一直执行本地队列，导致全局队列g的搁置。p 每执行 61 次调度，会从全局队列中获取一个 goroutine 进行执行。同时这其中涉及一些系统调用，比如gc等，所以实际会在61之前从全局中获取。</li><li>首先尝试从 p 本地队列中获取一个可执行的 goroutine，并且这个过程需要加锁<ul><li>由于存在work-stealing机制，需要加锁保正并发安全。窃取动作不会频繁发生，获取锁的概率很高，接近无锁化操作。</li></ul></li><li>如果本地队列没有可执行的g，从全局队列中获取</li><li>倘若本地队列和全局队列都没有 g，则会获取准备就绪的IO协程</li><li>如果上述还没有，尝试从其他P的本地队列，偷取一半的g<ul><li>一共会发起四次尝试，某一次成功即返回</li><li>偷取过程中会随机遍历P的起点位置，跳跃遍历，保证公平性</li><li>窃取目标P本地队列的一半，移动其头指针更新被偷取的队列信息</li></ul></li></ul><h3 id="execute"><a href="#execute" class="headerlink" title="execute"></a>execute</h3><ul><li><p>更新 g 的状态信息，建立 g 与 m 之间的绑定关系</p></li><li><p>更新 p 的总调度次数</p></li><li><p>调用 gogo 方法，执行 goroutine 中的任务</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息队列</title>
      <link href="/2023/07/12/5-MQ/"/>
      <url>/2023/07/12/5-MQ/</url>
      
        <content type="html"><![CDATA[<h2 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h2><p>消息队列的本质是传递消息的中间件，中间件并不关心底层的实现。常用的消息队列中间件间有kafka、RocketMQ、RabbitMQ。</p><p>通过MQ可以实现：</p><ul><li>解耦，把任务完成的通知交给消息队列</li><li>削峰，请求交给队列，逐步处理</li><li>提速，发送请求后，返回成功，异步处理任务，变相提高了对外提供的接口的处理能力（QPS）</li><li>通知多人，丢一条消息到MQ，多人自己拉取，或者MQ通知</li></ul><h2 id="Redis中实现消息队列"><a href="#Redis中实现消息队列" class="headerlink" title="Redis中实现消息队列"></a>Redis中实现消息队列</h2><h3 id="List"><a href="#List" class="headerlink" title="List"></a>List</h3><h3 id="Pub-Sub"><a href="#Pub-Sub" class="headerlink" title="Pub&#x2F;Sub"></a>Pub&#x2F;Sub</h3><h3 id="Stream"><a href="#Stream" class="headerlink" title="Stream"></a>Stream</h3><h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><h2 id="选型"><a href="#选型" class="headerlink" title="选型"></a>选型</h2>]]></content>
      
      
      
        <tags>
            
            <tag> MQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang | 垃圾回收机制</title>
      <link href="/2023/06/13/10-GC/"/>
      <url>/2023/06/13/10-GC/</url>
      
        <content type="html"><![CDATA[<blockquote><p>参考文章：</p><ol><li><a href="https://mp.weixin.qq.com/s/TdekaMjlf_kk_ReyPvoXiQ">小徐先生的编程世界——垃圾回收原理分析</a></li></ol></blockquote><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>垃圾回收（Garbage Collection，简称 GC）是一种内存管理策略，由垃圾收集器以类似<strong>守护协程</strong>的方式在后台运作，按照既定的策略为用户回收那些不再被使用的对象，释放对应的内存空间。</p><p>通过 GC 带来的优势：</p><ol><li>屏蔽了内存回收的细节，用户只需要专注业务逻辑</li><li>以全局视野执行任务，减少开发者手动对模块间内存管理的负担</li></ol><p>GC不足之处，提高了下限降低了上限，增加了额外成本，但是除了处理极少数对于极致速度追究的项目，GC带来的收益是极大的。</p><h2 id="垃圾回收算法"><a href="#垃圾回收算法" class="headerlink" title="垃圾回收算法"></a>垃圾回收算法</h2><ol><li>标记清除</li></ol><ul><li>先标记当前存活的对象，再清扫未被标记的垃圾对象；</li><li>不足之处，会出现<strong>内存碎片</strong>。</li></ul><ol start="2"><li>标记压缩</li></ol><ul><li>在标记清扫的基础上，会将存储对象进行压缩，使得整体空间更加紧凑，解决内存碎片问题</li><li>但是<strong>压缩复杂度过高</strong></li></ul><ol start="3"><li>半空间复制</li></ol><ul><li>分配两片相等大小的空间，fromspace和topspace</li><li>每轮只使用fromspace空间，以GC划分轮次</li><li>GC时，将fromspace存活对象转移到topspace中，进行空间压缩</li><li>GC结束后，交换两个空间</li><li>在标记压缩基础上，降低了复杂度，但是<strong>浪费空间</strong></li></ul><ol start="4"><li>引用次数</li></ol><ul><li>对象每被引用一次，计数器加1</li><li>对象每被删除引用一次，计数器减1</li><li>GC时，把计数器等于 0 的对象删除</li><li>不足之处，无法解决<strong>循环引用或者自引用</strong>问题，导致无法正常回收</li></ul><h2 id="Golang中的垃圾回收"><a href="#Golang中的垃圾回收" class="headerlink" title="Golang中的垃圾回收"></a>Golang中的垃圾回收</h2><p>Golang 的gc经历了以下几个版本：</p><ul><li><p>1.3版本前：普通标记清除法，整个gc过程需要启动 STW，效率极低</p></li><li><p>1.5版本：三色标记法，堆空间启动写屏障，栈空间不启动，全部扫描之后，需要重新扫描一次栈(需要 STW)，效率普通</p></li><li><p>1.8 版本：三色标记法，混合写屏障机制：栈空间不启动（根节点可达对象和新加入的对象全部标记成黑色），堆空间启用写屏障，整个扫描过程不要 STW，在开启和关闭写屏障时开启STW，效率高。</p></li></ul><h3 id="标记清除法"><a href="#标记清除法" class="headerlink" title="标记清除法"></a>标记清除法</h3><p>在<strong>go1.3</strong>之前采用标记清除法，从根对象出发，依次遍历对象以及子对象，标记对象的可达状态，然后清除未被标记的不可达对象，将空闲的内存加入到空闲链表中。</p><p>实现简单，但是标记前需要暂停程序（<strong>STW，stop the world</strong>），来避免回收写冲突问题，并且清除数据会导致内存碎片。</p><p>执行标记清除算法需要STW严重影响程序性能，因此在<strong>1.5</strong>版本开始，使用三色标记法来优化这个问题，支持<strong>并发垃圾回收机制</strong>。</p><h3 id="三色标记法"><a href="#三色标记法" class="headerlink" title="三色标记法"></a>三色标记法</h3><p>为了解决标记清除算法带来的长时间的STW，多数现代的垃圾收集器都会采用三色标记算法。该算法将程序中的对象分为白色、灰色和黑色三类：</p><ul><li>白色：潜在垃圾，是未被垃圾回收器访问到的对象，回收结束后，白色对象的内存会被释放</li><li>灰色：活跃对象，已经被垃圾回收器访问到，但存在指向白色对象的指针，需要继续访问其子对象</li><li>黑色：活跃对象，已经被垃圾回收器访问到，所有对象都遍历完</li></ul><p><img src="/../images/gc1.png" alt="output"></p><ul><li>第一步应用程序开始运行时，所有对象默认标记为白色</li><li>第二步遍历根节点（通常是协程上的对象，全局数据区的对象），把遍历到的对象标记为灰色<ul><li>A、E为灰色</li><li>其他为白色</li></ul></li><li>第三步遍历灰色对象，将灰色对象标记位黑色（因为他的next节点被遍历了），如果他的后继节点存在，标记为灰色（后续访问）<ul><li>A、E为黑色</li><li>B、C、F为灰色</li><li>其他为白色</li></ul></li><li>第四步重复第三步，直到灰色为空<ul><li>A、B、C、E、F、F为黑色</li><li>D、G、I、J为白色，不可达</li></ul></li><li>清除所有白色</li></ul><h3 id="漏标问题"><a href="#漏标问题" class="headerlink" title="漏标问题"></a>漏标问题</h3><p>因为应用程序可能在标记执行的过程中，修改对象的引用关系，所以<strong>为了保证对象不被错误回收</strong>，仍需要STW。否则可能会出现漏标和多标问题。</p><p>假设当前已经完成第一轮扫描，如下图所示。此时灰色对象F通过p指针指向白色对象H。</p><p><img src="/../images/gc2.png" alt="5ac8d27d-ed33-4af0-b55f-a178c57bedc1"></p><p>当对象E标记为黑色，F还未扫描，创建q指针使得对象E指向白色对象H，并移除F指向H指针。</p><p><img src="/../images/gc3.png" alt="94db6bea-fc0c-46ea-8db4-4d7239f21440"></p><p>此时由于E完成了扫描，F移除了H遍历，不会遍历到H，导致H为白色不可达，被错误回收。</p><p>综上分析，在不执行STW时，满足下面两个条件下会破坏垃圾收集器的正确性：</p><ul><li><p>条件1：某个黑色对象引用白色对象（q指针）</p></li><li><p>条件2：从灰色对象出发，到达白色对象的、<strong>未经访问过的路径遭到破坏</strong>（F—&gt;H)</p></li></ul><h3 id="多标问题"><a href="#多标问题" class="headerlink" title="多标问题"></a>多标问题</h3><p><img src="/../images/gc2.png" alt="5ac8d27d-ed33-4af0-b55f-a178c57bedc1"></p><p>同样可能出现多标问题。在E完成标记后置黑，F标记位灰色，在另一个时刻，一个协程删除了E对F的引用，F应该变成垃圾对象，但是由于E已经完成扫描，F最终被置为黑色，导致多标问题。</p><p>本该被删但仍侥幸存活的对象被称为“浮动垃圾”，至多到下一轮GC（重置标记，发现不可达），这部分对象就会被GC回收，因此错误可以得到弥补，多标问题一般可以忽略。</p><h2 id="屏障技术"><a href="#屏障技术" class="headerlink" title="屏障技术"></a>屏障技术</h2><p>多标问题在下一轮GC可以得到解决，而漏标问题为了避免上述问题出现，只需要达到以下两种三色不变性的一种：</p><ul><li>强三色不变性：黑色对象不会指向白色对象，只会指向灰色对象或黑色对象</li><li>弱三色不变性：黑色对象指向的白色对象，必须包含一条从灰色对象经由多个白色对象的可达路径</li></ul><p>当遵循强三色不变性或弱三色不变性时，我们能够保证垃圾收集的正确性，而屏障技术就是在并发或增量标记过程中保证三色不变性的重要技术。</p><p>Go语言在垃圾收集器的演进过程中，采用Dijkstra提出的插入写屏障和Yuasa提出的删除写屏障。</p><h3 id="插入写屏障"><a href="#插入写屏障" class="headerlink" title="插入写屏障"></a>插入写屏障</h3><p><img src="/../images/gc4.png" alt="图片"></p><p>为了避免<strong>漏标问题</strong>，引入插入写屏障，在黑色对象引入一个白色对象时，将白色对象标记为灰色，满足强三色不变性。</p><p>对象在内存槽中有两种位置：栈和堆。栈空间的特点是容量小，但要求响应速度快，所以Go语言<strong>没有选择启用栈上的写屏障机制</strong>。</p><blockquote><p>几乎大部分操作都在栈上完成，如果设置插入写屏障，写屏障需要执行的次数很多，比再扫描一遍成本高。</p></blockquote><h3 id="删除写屏障"><a href="#删除写屏障" class="headerlink" title="删除写屏障"></a>删除写屏障</h3><p><img src="/../images/gc5.png" alt="图片"></p><p>删除写屏障（Yuasa barrier）的目标是实现弱三色不变式，保证当一个白色对象即将被上游删除引用前，会触发屏障将其置灰，之后再删除上游指向其的引用，解决漏标问题。</p><h3 id="混合写屏障"><a href="#混合写屏障" class="headerlink" title="混合写屏障"></a>混合写屏障</h3><p>插入写屏障、删除写屏障二者择其一，即可解决并发GC的漏标问题，至于错标问题，则采用容忍态度，放到下一轮GC中进行延后处理即可。</p><p>但是真实场景下，屏障机制无法作用于栈对象，引入STW成本过高，为此Golang1.8引入了混合写屏障：</p><ul><li>GC 开始前，以栈为单位分批扫描，将栈中所有对象置黑</li><li>GC 期间，栈上新创建对象直接置黑</li><li>堆对象正常启用插入写屏障</li><li>堆对象正常启用删除写屏障</li></ul><p>可以看<a href="https://mp.weixin.qq.com/s/TdekaMjlf_kk_ReyPvoXiQ">小徐先生的编程世界——垃圾回收原理分析</a>，通过混合写屏障，保障了在栈上不会出现漏标问题，而多标问题延后处理。</p><blockquote><p>通常，在垃圾回收的扫描阶段开始时，栈上的对象会被认为是根对象（root objects）。因为它们是从根开始的可达对象，所以要被标记为黑色。根对象通常是不可回收的，因为它们是当前执行上下文的一部分，并且引用其他对象。</p></blockquote><h2 id="golang如何解决内存碎片问题"><a href="#golang如何解决内存碎片问题" class="headerlink" title="golang如何解决内存碎片问题"></a>golang如何解决内存碎片问题</h2><p>golang采用标记清扫算法，但是标记清扫算法会出现内存碎片问题，如何化解这一问题：</p><p>golang采用tcmalloc机制，实现将内存分块到不同的spanClass，申请时分配合适大小的块，将问题限制在可控的范围。词用采用更为简单的标记清除法，比标记压缩算法复杂度低很多。</p><h2 id="有了GC是否不会发生内存泄露"><a href="#有了GC是否不会发生内存泄露" class="headerlink" title="有了GC是否不会发生内存泄露"></a>有了GC是否不会发生内存泄露</h2><p>不一定，当预期能够很快被释放的内存，由于附着在长期存活的内存、或生命期被意外延长，依然会导致长时间得不到回收。比如：</p><ul><li>预期能被快速释放的内存因被根对象引用而没有得到迅速的释放</li><li>当有一个全局对象时，可能不经意间将某个变量附着在其上，且忽略释放该变量，则其内存永远不会得到释放。</li><li>Goroutine作为一种逻辑上理解的轻量级线程，需要维护执行用户代码的上下文信息。在运行过程中也需要消耗一定的内存来保存这些信息，而这些内存在目前版本的Go语言是不会被释放的。因此，当一个程序持续不断地产生新的Goroutine、且不结束已创建的Goroutine并复用这部分内存，就会造成内存泄露的现象</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang | 内存模型与分配机制</title>
      <link href="/2023/06/12/9-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"/>
      <url>/2023/06/12/9-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<blockquote><p>参考文章：</p><ol><li><a href="https://space.bilibili.com/567195437">幼麟实验室</a></li><li><a href="https://mp.weixin.qq.com/s/2TBwpQT5-zU4Gy7-i0LZmQ">小徐先生的编程世界——内存模型与分配机制</a></li></ol></blockquote><h2 id="内存模型"><a href="#内存模型" class="headerlink" title="内存模型"></a>内存模型</h2><p>操作系统中经典的<strong>多级存储模型</strong>包括寄存器、高速缓存、内存、磁盘，从左到右速度更慢，空间更大，价格更低。</p><p>另一个重要的概念是<strong>虚拟内存</strong>，其作用如下：</p><ul><li>在用户与硬件间添加中间代理层（没有什么是加一个中间层解决不了的）</li><li>优化用户体验（进程感知到获得的内存空间是“连续”的）</li><li>“放大”可用内存（虚拟内存可以由物理内存+磁盘补足，并根据冷热动态置换，用户无感知）</li></ul><p>操作系统中通常会将虚拟内存和物理内存切割成固定的尺寸，于虚拟内存而言叫作<strong>“页”</strong>，于物理内存而言叫作<strong>“帧”</strong>，原因及要点如下：</p><ul><li>提高内存空间利用（以页为粒度后，消灭了不稳定的外部碎片，取而代之的是相对可控的内部碎片）</li><li>提高内外存交换效率（更细的粒度带来了更高的灵活度）</li><li>与虚拟内存机制呼应，便于建立虚拟地址-&gt;物理地址的映射关系（聚合映射关系的数据结构，称为<strong>页表</strong>）</li><li>linux 页&#x2F;帧的大小固定，为 4KB（这实际是由实践推动的经验值，太粗会增加碎片率，太细会增加分配频率影响效率）</li></ul><h2 id="golang内存模型"><a href="#golang内存模型" class="headerlink" title="golang内存模型"></a>golang内存模型</h2><p>当程序运行起来所需分配的内存块有大有效，如果随机分配然后取用，分散的、大小不一的碎片化内存一方面会<strong>降低内存的使用率</strong>，也会增加下一次申请内存块的代价。</p><p>为了降低碎片化内存带来的影响，go采用了Tcmalloc内存分配器相似的算法。主要包括以下要点：</p><ul><li>将内存页按照预制的大小规格进行分块，不同规格的内存块分到对应的空闲链表当中</li><li>程序申请内存时，分配器会优先根据申请的内存大小找到最匹配的规格，然后从对应的空闲链表中分配一个内存块</li></ul><p><img src="/../images/mp4.png" alt="图片"></p><p>管理堆内存的数据结构主要包括管理整个堆内存的mheap，管理其中每个Arena的heapArena，管理span的mspan，以及管理全局mspan的mcentral</p><ul><li><p>堆内存可以划分一块块64MB的Arena，每个Arena具体可以张开为8192个page，每个page即8K大小，page作为<strong>最小的存储单元</strong></p></li><li><p>在这个基础上多个page又组合成不同的span，span中按照特定规格划分成等大的内存块，作为<strong>最小的管理单元</strong></p><p><img src="/../images/m1.png" alt="m1"></p><ul><li>同等级的span从属同一个mcentral，最终组织成一个链表（携带前后指针）</li><li>这样同一个等级的span可以基于同一把互斥锁管理，mcentral级别的锁</li><li>通过位图可以辅助快速找到空闲的内存块，在GC时候也会结合这部分处理</li><li>总共有68种class大小，分配一个大小时根据class的object大小进行选择，不足时会补齐，所以仍然会有个内部空间浪费</li></ul></li><li><p>不同P之间获取内存，为了并发安全，需要加锁</p><ul><li>为了保障多个p之间并发安全，降低p之间的竞争性，go语言每个p都有一个本地的小对象缓存，从这里取用不需要加锁，如图中的线程缓存mcache。<strong>mcache是每个P独有的缓存，因此交互无锁</strong></li><li>mcache中包含了tiny allocator分配给小于16B的对象，以及每种spanClass等级的mspan，同时整体又分为需要GC进一步展开的scan和不需要进一步展开的noscan，68*2 &#x3D; 136</li><li>当需要使用时优先从本地的mcache获取，没有或者用完了某个规模，再去mcentral中申请</li></ul></li><li><p>heapArena中主要保存了各种重要的bitmap位图，用来记录各种状态，比如标记变量是指针还是标量，是否需要继续扫描等</p><p><img src="/../images/m2.png" alt="2e23e169e98adfdc1c0d3f4a7d873150a2a190ff9081aa621ffa7204c3c0d89b"></p><ul><li>heapArena 记录了页到 mspan的映射。因为 GC 时，通过地址偏移找到页很方便，但找到其所属的 mspan 不容易。 因此需要通过这个映射信息进行辅助</li></ul></li><li><p>中心缓存mcentral一个数组，维护了68 * 2种span，每个mcentral下聚合了该spanClass下的mspan</p><p><img src="/../images/m3.png" alt="854c5e3559565d6c275e251af039c4e6ef0f18a50d0dbd2b2578aacb1b9a0af4"></p><ul><li>同一个mspanClass下又分为有空间的和满空间的链表</li><li>每个mcentral中包含该类别的锁，降低的锁粒度</li></ul></li><li><p>此时全局堆缓存mheap，对于golang上层应用而言，堆是操作系统虚拟内存的抽象</p><ul><li>将连续页组装成mspan，基于位图标记全局内存的使用情况（是否被组装）</li><li>通过heapArena聚合页，记录页到mspan的映射信息，page到mspan</li><li>建立空闲页基数树索引 radix tree index，辅助快速寻找空闲页</li><li>持有所有 spanClass 下的 mcentral，作为自身的缓存</li><li>内存不够时，向操作系统申请，申请单位为 heapArena（64M）</li></ul></li></ul><p>核心思想以空间换时间，一次缓存，多次使用，避免重复申请内存；同时堆作为Go运行时中最大的临界共享资源，每次存取需要加锁，通过mcache无锁化访问。</p><h2 id="golang分配对象流程"><a href="#golang分配对象流程" class="headerlink" title="golang分配对象流程"></a>golang分配对象流程</h2><p>golang中根据对象的大小可以划分成三类</p><ul><li>tiny微对象：(0, 16B)</li><li>small小对象：[16B, 32KB]</li><li>large大对象：(32KB, ∞)</li></ul><p>不同的对象，分配流程不同，在mallocgc方法中通过类似读取多级缓存形式获取，</p><ol><li>从 P 专属 mcache 的 tiny 分配器取内存（无锁）</li><li>根据所属的 spanClass，从 P 专属 mcache 缓存的 mspan 中取内存（无锁）</li><li>根据所属的 spanClass 从对应的 mcentral 中取 mspan 填充到 mcache，然后从 mspan 中取内存（spanClass 粒度锁）</li><li>根据所属的 spanClass，从 mheap 的页分配器 pageAlloc 取得足够数量空闲页组装成 mspan 填充到 mcache，然后从 mspan 中取内存（全局锁）</li><li>mheap 向操作系统申请内存，更新页分配器的索引信息，然后重复（4）</li></ol><p>对于tiny从1到5，small执行2-5，large执行4-5步骤。large大对象直接从4，5开始，要分配class0de</p>]]></content>
      
      
      
        <tags>
            
            <tag> golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Bitcask | 论文阅读</title>
      <link href="/2023/05/12/3-Bitcask/"/>
      <url>/2023/05/12/3-Bitcask/</url>
      
        <content type="html"><![CDATA[<h2 id="Bitcask模型背景"><a href="#Bitcask模型背景" class="headerlink" title="Bitcask模型背景"></a>Bitcask模型背景</h2><p>bitcask 存储模型最初是由一个做分布式存储系统的商业化公司 Riak 提出来的。</p><p>Riak 有很多产品，其中就包括一个分布式 KV 存储系统 Riak KV，他们的分布式 KV 产品具有可插拔的存储引擎，可以独立于整个系统，单独开发和测试新的存储引擎。</p><p>基于此，他们想打造一个全新的存储引擎，在最理想的情况下，满足下面的这些条件：</p><ul><li><p>读写低延迟</p></li><li><p>高吞吐，特别是对大量的随机写入</p></li><li><p>能够处理超过内存容量的数据</p></li><li><p>崩溃恢复友好，能够保证快速恢复，尽量不丢数据</p></li><li><p>简单的备份和恢复策略</p></li><li><p>相对简单、易懂的代码结构和数据存储格式</p></li><li><p>在大数据量下，性能有保障</p></li><li><p>能够有自由的授权使用在 Riak 的系统中</p></li></ul><p>现有的存储引擎，没有一个能够很好的满足这些条件，于是 Riak 团队重新设计了一个简洁高效的存储引擎<a href="https://riak.com/assets/bitcask-intro.pdf">bitcask</a>。</p><h2 id="存储模型实例"><a href="#存储模型实例" class="headerlink" title="存储模型实例"></a>存储模型实例</h2><p><img src="/../images/bitcask-1.png" alt="image-20231005102033724"></p><p>Bitcask存储引擎最初的设计目标并不是追求最高的性能，而是追求足够的性能以及高质量、简单的代码设计和文件格式。</p><blockquote><p>However, our initial goal with Bitcask was not to be the fastest storage engine but rather to get ”enough” speed and also high quality and simplicity of code, design, and file format. </p></blockquote><p>最终实现的一个存储引擎实例，就是系统上的一个目录，并且限制同一时刻只能有一个进程进行写入。将一个进程看作数据库的服务端。</p><blockquote><p>这边在后续自己实现时，简化为每次只允许一个进程打开，通过文件锁来实现，读写操作并发问题通过锁保证。</p></blockquote><h3 id="数据文件"><a href="#数据文件" class="headerlink" title="数据文件"></a>数据文件</h3><p>在这个目录当中，存在多个数据文件，具体分为活跃文件和旧的数据文件（后续称为旧文件）：</p><ul><li>活跃文件仅存在打开数据库时，用于追加写入数据，追加写入性能更高。</li><li>活跃文件写入一定数据量时，活跃文件转为旧文件，旧文件主要用于数据读取。</li></ul><p>在每个数据文件中存储了具体的记录信息：</p><p><img src="/../images/bitcask-2.png" alt="image-20231005085420859"></p><ul><li>crc：数据校验，防止数据被破坏、篡改等</li><li>timestamp：写入数据的时间戳</li><li>ksz：key size，key 的大小</li><li>value_sz：value size，value 的大小</li><li>key：用户实际存储的 key</li><li>value：用户实际存储的 value</li></ul><p>对于Put相当于写入一条记录到活跃文件，而Delete写入一条特殊的墓碑记录，标记前面的记录失效，而不是直接删除某条数据。在下次Merge过程中，才会清理无效的数据。</p><h3 id="内存索引"><a href="#内存索引" class="headerlink" title="内存索引"></a>内存索引</h3><p>回顾Bitcask模型的设计初衷，”能够处理超过内存容量的数据“，所以Bitcask在内存索引中维护Value实际是存储在磁盘中的文件ID，偏移，记录大小。</p><p><img src="/../images/bitcask-3.png" alt="image-20231005102126621"></p><p>在数据追加写入到磁盘当中后，更新内存中的数据结构keydir，实际上就是key的一个集合，存储是key到磁盘文件的位置。</p><p>keydir中存放了一条数据在磁盘中最新的数据，尽管旧的数据仍然存在，在加载或者更新时会使用最新的数据，在后续merge操作中清理无效数据。</p><blockquote><p>在论文中提到使用哈希表来存储，这里可以自由选择，常见可以选择BTree，B+Tree，ART，跳表等。</p><p>例如哈希表，可以更高效的获取数据，但是无法遍历数据，如果想要数据有序遍历，可以选择 B 树、跳表等天然支持排序的数据结构。</p></blockquote><h3 id="数据读写"><a href="#数据读写" class="headerlink" title="数据读写"></a>数据读写</h3><p><img src="/../images/bitcask-4.png" alt="image-20231005102945464"></p><p>在了解完数据文件和内存索引后，数据读取也清晰明了。首先根据key从内存中找到对应的记录，拿到记录实际在磁盘中的位置，根据位置找到磁盘中对应的数据文件，获取到完整的数据返回。</p><p>由于旧的数据实际上一直存在于磁盘文件中，因为我们并没有将旧的数据删掉，而是新追加了一条标识其被删除的记录。因此论文当中提出了merge过程清理无效数据，避免旧的数据过多。merge 会遍历所有不可变的旧数据文件，将所有有效的数据重新写到新的数据文件中，并且将旧的数据文件删除掉。</p><p>此外，由于数据存放在磁盘文件中，每次需要手动加载数据到内存索引中。当数据积累到一定量时，如果发生数据库重启，加载时间过长对业务造成一定的影响，因此论文当中提出，在merge过程中将有效数据写入到一个hint文件中，hint文件类似数据文件，不过它存储的时记录的位置信息。</p><p>当bitcask启动时，直接加载hint文件中的数据，再加载未合并的数据，从而达到快速构建索引目的。</p><h3 id="API接口"><a href="#API接口" class="headerlink" title="API接口"></a>API接口</h3><pre class=" language-shell"><code class="language-shell">// 打开一个 bitcask 数据库实例，使用传入的目录路径// 需要保证进程对该目录具有可读可写权限bitcask::Open(Directory Name);// 通过 Key 获取存储的 valuebitcask::Get(Key);// 存储 key 和 valuebitcask::Put(Key, Value);// 删除一个 keybitcask::Delete(Key);// 获取全部的 keybitcask::list_keys();// 遍历所有的数据，执行函数 Funbitcask::Fold(Fun);// 执行 merge，清理无效数据bitcask::Merge(Directory Name);// 刷盘，将所有缓冲区的写入持久化到磁盘中bitcask::Sync();// 关闭数据库bitcask::Close();</code></pre><h2 id="整体回顾"><a href="#整体回顾" class="headerlink" title="整体回顾"></a>整体回顾</h2><p>Bitcask存储引擎是一个KV存储引擎，相比于Redis，通过将实际Value维护在磁盘中，能够处理超过内存容量的数据。</p><p>回顾论文开头，Riak 团队提出的期望：</p><ul><li>首先，bitcask 很快，查询和写入都很快，因为读写都只有一次磁盘 IO</li><li>写入数据还是顺序 IO，保证了高吞吐</li><li>内存中不会存储实际的 value，因此在 value 较大的情况下，能够处理超过内存容量的数据</li><li>提交日志和数据文件实际上就是同一个文件，数据的崩溃恢复能够得到保证</li><li>备份和恢复非常简单，只需要拷贝整个数据目录即可</li><li>设计简洁，数据文件格式易懂、易管理</li></ul><p>总体来说，bitcask 基本满足了设计的要求，是一个简洁优雅、高效的存储引擎。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 是什么 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx是什么</title>
      <link href="/2023/05/03/2-ngnix/"/>
      <url>/2023/05/03/2-ngnix/</url>
      
        <content type="html"><![CDATA[<h2 id="正向-反向代理"><a href="#正向-反向代理" class="headerlink" title="正向 &#x2F; 反向代理"></a>正向 &#x2F; 反向代理</h2><p>当我们想要探索外面的世界时，使用的魔法，就相当于一个正向代理，将请求发送给代理服务器，代理服务器访问国外网站后将数据转发给我们。</p><p>通过正向代理屏蔽了真实的客户端信息，对外隐藏用户信息，同时可以记录用户访问记录；此外可以对客户端访问授权，上网进行认证。</p><p>淘宝双十一时，同时在线的人数巨大，单个服务器远不能满足人们日益增长的需求。由此引出了<strong>分布式部署</strong>，通过多台服务器解决访问人数首先问题，实现负载均衡，Nginx在这其中担任了反向代理服务器的职责。</p><p>当多个客户端发送请求给服务器，Nginx服务器收到请求后，按照一定规则分发给后端的业务处理服务器。</p><p>反向代理，代理的是<strong>服务端一侧</strong>，隐藏了服务器的信息，客户端无感知代理的存在，用户请求发送到Nginx一侧，再具体分发给服务器处理。</p><p>反向代理服务器除了<strong>优化网站的负载</strong>以外，还可以将反向代理设置为公网访问地址，Web服务器是内网，<strong>保证内网的安全</strong>。</p><p><a href="../images/nginx-1.png"></a></p><h2 id="关于Ngnix"><a href="#关于Ngnix" class="headerlink" title="关于Ngnix"></a>关于Ngnix</h2><p>简单来说，Nginx是一款轻量级的Web服务器，采用事件驱动的异步非阻塞处理方式框架，这让其具有极好的 IO 性能，时常用于服务端的<strong>反向代理</strong>和<strong>负载均衡</strong>。</p><blockquote><p>Web服务器：负责处理和响应用户请求，一般也称为http服务器，如 Apache、IIS、Nginx。</p><p>应用服务器：存放和运行系统程序的服务器，负责处理程序中的业务逻辑，如 Tomcat、Weblogic、Jboss（现在大多数应用服务器也包含了web服务器的功能）。</p></blockquote><p>一个基本Nginx进程模型，包括了：</p><ul><li>master进程，有且只有一个，负责读取验证配置文件，以及管理worker进程；</li><li>work进程，负责处理实际的请求，存在多个。</li></ul><h3 id="为什么选择Nginx"><a href="#为什么选择Nginx" class="headerlink" title="为什么选择Nginx"></a>为什么选择Nginx</h3><p>Nginx居然以下优点：</p><ul><li><p>一种轻量级的web服务器</p></li><li><p>Nginx 安装简单，配置简洁，作用却无可替代</p></li><li><p>占用内存少、启动速度快、并发能力强</p></li><li><p>扩展好，第三方插件多</p></li><li><p>…</p></li></ul><h3 id="动静分离"><a href="#动静分离" class="headerlink" title="动静分离"></a>动静分离</h3><p>Nginx服务器将收到的请求划分为动态请求和静态请求：</p><ul><li>静态请求直接从 nginx 服务器所设定的根目录路径去取对应的资源，直接返回。</li><li>动态请求转发给真实的后台（前面所说的应用服务器，如图中的Tomcat）去处理。</li></ul><p>这样做能够减轻应用服务器（实现具体后端业务逻辑）压力，将后台api接口服务化，将前后端代码分开并行开发和部署。</p><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><p>随着业务的不断增长和用户不断增多，使用服务器集群提升业务性能和用户体验。</p><p>Nginx在实现反向代理功能基础上，通过负载均衡算法算法实现请求的合理分配。常用的负载均衡调度算法包括以下：</p><ul><li><p><strong>weight轮询</strong>（默认，常用）：赋予每一台的后端机器不同的权重值（weight），权重值越大，被分配到请求的几率越大，主要根据工作环境中后端服务器硬件配置进行调整。</p></li><li><p><strong>ip_hash</strong>(常用)：每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器。这也在一定程度上解决了集群部署环境下session共享的问题。</p></li><li><p><strong>url_hash</strong>：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在Nginx作为静态服务器的情况下提高缓存效率。使用的话需要安装Nginx的hash软件包。</p></li></ul><p>此外Nginx还带有<strong>健康检查</strong>功能，会定期轮询集群里所有服务器发送健康检查请求，当集群中某个服务器异常时，后续请求不会分发到该处，知道下一次健康检查时，服务器恢复正常。</p><blockquote><p>参考文章</p><ul><li><a href="https://www.cnblogs.com/wcwnina/p/8728391.html">博客园-Nginx相关介绍</a></li><li><a href="https://juejin.cn/post/6844904129987526663">掘金-连前端都看得懂的《Nginx入门》…</a></li></ul></blockquote><h3 id="HTTPS配置"><a href="#HTTPS配置" class="headerlink" title="HTTPS配置"></a>HTTPS配置</h3><p>需要使用SSL证书，主流都能申请到，对应pem为证书文件，key为私钥文件，放到nginx中；</p><p>一般都会配置一个重定向来让 HTTP 的请求自动跳转到https。</p><h3 id="虚拟主机"><a href="#虚拟主机" class="headerlink" title="虚拟主机"></a>虚拟主机</h3><p>很多时候一个网站在起步阶段并没有非常大的访问量，把多个网站部署在一起也不会对服务器造成太大的压力，而且这样可以节省服务器的资源和成本；</p><p>每个server对应一个虚拟主机，server_name指定虚拟主机的域名，当我们访问这个域名的时候，就会被这个 Server 块所匹配，然后就会执行这个 Server 块中的配置。这样就可以在一台服务器上配置多个虚拟主机了；</p><p>一般会把多个虚拟主机的配置信息，放到一个server文件中，最后include，做统一管理；</p><p><a href="../images/nginx-2.png"></a></p><h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><ol><li>通过编译安装方式，预编译，编译，安装；</li></ol><pre class=" language-shell"><code class="language-shell">./configuremake make install</code></pre><ol start="2"><li>Linux安装成功，没有消息表示成功（Linux系统特点）；</li><li>sudo nginx启动nginx；</li><li>Nginx -V 查看信息，包含了配置文件的信息；</li><li>ps -ef | grep nginx，查看对应进程信息；</li><li>lsof -i :80，查看端口的占用情况</li><li>sudo nginx -s stop &#x2F; quit &#x2F; reload &#x2F; reopen，分别为优雅停止、立即停止、重载配置文件、重新打开日志文件</li><li>常用nginx -V或者nginx -t 查看常见位置信息；</li><li>当我修改了配置文件，需要nginx -s reload重新运行配置文件；</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 是什么 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统 | IO多路复用</title>
      <link href="/2023/04/17/12-IO/"/>
      <url>/2023/04/17/12-IO/</url>
      
        <content type="html"><![CDATA[<h2 id="最基本的Socket模型"><a href="#最基本的Socket模型" class="headerlink" title="最基本的Socket模型"></a>最基本的Socket模型</h2><p>Socket模型相比管道、共享内存、信号量等方式，实现了跨主机进程之间的通信，但是他是<strong>阻塞IO模型</strong>，基本上只能一对一通信，当发生读写阻塞时，会导致其他客户端请求无法处理，无法建立新的连接。</p><h2 id="传统方式"><a href="#传统方式" class="headerlink" title="传统方式"></a>传统方式</h2><p>传统方式每一个客户端连接，就分配一个进程或者线程，通过多线程、多进程方式实现一对多的通信。</p><h3 id="多进程模型"><a href="#多进程模型" class="headerlink" title="多进程模型"></a>多进程模型</h3><p>主要思路如下：</p><ul><li>服务器主线程负责监听客户端连接，建立连接后accept函数返回一个已连接的socket</li><li>同时fork出一个子进程，子进程复制了父进程相关的资源，通过父进程的文件描述符实现了与客户端通信</li></ul><p>在子进程退出时，需要做好回收工作，否则变成<strong>僵尸进程</strong>，会占用系统资源。</p><blockquote><p>僵尸进程：子进程先于父进程结束时，子进程的退出状态信息会被保留，但其父进程没有及时对其进行处理，导致子进程变为僵尸进程。僵尸进程不再执行任何代码，但其占用系统资源，如进程表中的一个记录。</p></blockquote><p>随着客户端数量增多，每产生一个进程会占用一定的系统资源，并且进程间的上下文成本很高，性能会收到影响。因此多进程模型并不合适。</p><h3 id="多线程模型"><a href="#多线程模型" class="headerlink" title="多线程模型"></a>多线程模型</h3><p>多进程的上下文切换成本很高，可以联想到多线程模型。同进程里的线程可以共享进程的部分资源，比如文件描述符列表、进程空间、代码、全局数据、堆、共享库等，这些共享些资源在上下文切换时不需要切换，而只需要切换线程的私有数据、寄存器等不共享的数据。</p><p>主要思路如下：</p><ul><li>主线程负责监听客户端连接，当完成客户端TCP连接后，创建线程，传递已连接的socket的文件描述符给线程函数</li><li>在线程里完成与客户端的通信，达到并发处理</li></ul><p>每次连接来创建一个线程，结束后在销毁，创建和销毁的成本较高，由此引入了<strong>线程池</strong>概念，提前创建若干个线程，通过复用线程减少性能损失。由于队列是全局的，为了避免多线程竞争，线程在操作时需要加锁。</p><p>但是实际中在高并发场景下，维护1万个进程或者线程，操作系统都是无法扛得住的。由此引入了I&#x2F;O多路复用技术。</p><h2 id="I-O多路复用"><a href="#I-O多路复用" class="headerlink" title="I&#x2F;O多路复用"></a>I&#x2F;O多路复用</h2><p>通过一个进程维护多个socket通信。每个进程控制每个请求处理耗时，并发处理多个请求，实现一个时分多路复用，类似一个CPU并发处理多个进程。</p><p>总体思路：将所有已经建立的连接（文件描述符）传递给内核，再由内核返回产生事件的连接，最终在用户态处理连接对应的请求。</p><h3 id="select"><a href="#select" class="headerlink" title="select"></a>select</h3><p>大致思路如下：</p><ul><li>将已连接的 Socket 都放到一个<strong>文件描述符集合</strong>，然后调用 select 函数将文件描述符集合<strong>拷贝</strong>到内核里，让内核通过<strong>遍历集合</strong>是否有网络事件产生，将对应产生事件的socket标为可读或者可写</li><li>再将文件描述符拷回用户态，用户态经过<strong>遍历集合</strong>找到可读或者可写的socket</li></ul><p>select使用固定长度的bitmap表示文件描述符集合，个数受限。在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 <code>1024</code>，只能监听 0~1023 的文件描述符。</p><h3 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h3><p>poll改进了select方式，使用动态数组存储文件描述符集合。但是仍然需要两次用户态和内核态之间拷贝，通过遍历方式检查可读可写。</p><h3 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h3><p>epoll通过两种方式，解决了select&#x2F;poll问题：</p><ul><li>epoll 在内核里使用<strong>红黑树</strong>来跟踪进程所有待检测的文件描述字，可以用来保存待检测的socket，不需要重复拷贝</li><li>epoll 使用<strong>事件驱动</strong>的机制，内核里维护了一个<strong>链表来记录就绪事件</strong>，当某个 socket 有事件发生时，通过<strong>回调函数</strong>内核会将其加入到这个就绪事件列表中，通过epoll_wait获取返回有事件的文件描述符个数，避免轮询查找事件。</li></ul><p>此外epoll相比select、poll还支持了边缘触发方式，默认这三种都是选择水平触发方式。</p><blockquote><p><strong>水平触发</strong>：当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取。</p><p><strong>边缘触发</strong>：当被监控的 Socket 描述符上有可读事件发生时，<strong>服务器端只会从 epoll_wait 中苏醒一次</strong>，即使没有被读取，也不会重复唤醒，所以要尽可能保证一次性读取完。</p></blockquote><p>通过边缘触发方式，可以减少epoll_wait调用的方式，减少开销（上下文切换），一般为了避免由于实际文件描述符是阻塞的，没有可以读写造成进程阻塞，边缘触发一般搭配非阻塞I&#x2F;O使用。</p><blockquote><p>实际I&#x2F;O多路复用一般最好搭配非阻塞I&#x2F;O使用，因为多路复用 API 返回的事件并不一定可读写的，如果使用阻塞 I&#x2F;O， 那么在调用 read&#x2F;write 时则会发生程序阻塞。</p></blockquote><blockquote><p>后话，如果放到现在再去看去年webserver的内容，可能理解又不一样了。</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统 | 进程间通信</title>
      <link href="/2023/04/15/11-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"/>
      <url>/2023/04/15/11-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>参考文章：</p><ol><li><a href="https://xiaolincoding.com/os/4_process/process_commu.html">小林coding</a></li><li><a href="https://www.bilibili.com/video/BV1EW411u7th/">Crash Course Computer Science</a></li></ol></blockquote><h2 id="进程间通信"><a href="#进程间通信" class="headerlink" title="进程间通信"></a>进程间通信</h2><p>每个进程之间的用户地址空间是独立的，一般不能互相访问，但是<strong>内核空间</strong>是每个进程都共享的，所以进程之间要通信必须通过内核。</p><p>进程间通信方式包括：</p><ul><li>管道</li><li>信号量</li><li>条件变量</li></ul><h2 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h2><h3 id="匿名管道"><a href="#匿名管道" class="headerlink" title="匿名管道"></a>匿名管道</h3><pre class=" language-shell"><code class="language-shell">ps auxf | grep mysql</code></pre><p>在上述中<code>|</code>就是一个管道，通过管道将前一个输出作为下一条指令的输入，由此可见匿名管道是<strong>单向的</strong>。如果想要相互通信，需要创建两个管道。</p><p>匿名管道是<strong>单向的</strong>（单个管道），<strong>只存在内存中</strong>，相当于<strong>内核中的一串缓存</strong>，读写都是在内核中完成，并且是<strong>无格式的流并且大小受限</strong>。</p><h3 id="命名管道"><a href="#命名管道" class="headerlink" title="命名管道"></a>命名管道</h3><p>与匿名管道对应是命名管道，也被叫做FIFO（是一个先进先出的数据结构），使用前需要通过<code>mkfifo pipiName</code>来创建管道，实际是以<strong>文件</strong>形式存在。</p><p>命名管道是阻塞读写的，写入后必须等待另一个进程读出，才会恢复，因此通信方式效率低，不适合进程间频繁地交换数据。</p><h3 id="跨进程通信"><a href="#跨进程通信" class="headerlink" title="跨进程通信"></a>跨进程通信</h3><p>通常当我们使用匿名管道进行进程间通信，需要创建两个管道，才能完成。</p><p>匿名管道是如何跨进程通信的：</p><ul><li>在一个进程中，通过fork创建子进程，子进程会复制父进程的文件描述符，实现了父进程和子进程分别持有fd[0]和fd[1]，实现跨进程通信。</li><li>同时为了避免同时读写的混论问题，通常关闭一段读端只保留写端，一端只保留读端关闭写端。</li></ul><p>以上是通过两个匿名管道实现进程间通信，在shell中并不是这样的，<code>A | B</code>都是shell创建出的子进程，不存在父子进程关系，但他们的父进程都是shell，实现了进程间通信。</p><p>对于没有实体文件的匿名管道，通信范围局限在父子进程当中，通过fork来复制父进程的文件描述符，实现通信。</p><p>对于命名管道，可以通过文件在不相关的进程间实现通信，不同进程可以打开创建的FIFO文件来访问同一个管道进行通信，结束后需要关闭管道释放相关资源。</p><p>无论是匿名管道还是命名管道，最终数据都是存放在内核当中。</p><h2 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h2><p>通过管道的通信效率低（<strong>写入数据会阻塞，直到数据被读取</strong>），不适合频繁交换数据。消息队列可以解决这个问题。</p><p>数据写入时写入到<strong>内核中的消息链表</strong>，并且消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。</p><p>当进程从消息队列中读取了消息体，内核会把这个消息体删除。消息队列需要手动释放或者等待操作系统关闭。</p><p>但是消息队列仍有两个不足：</p><ul><li>不适合大数据的传输，因为内核中每个消息体都有最大长度限制，最终导致队列的消息体的总长度也有限制。</li><li>存在用户态与用户态的数据拷贝开销，数据写入到内核中的消息队列和读取，都需要涉及用户态和内核态之间数据的拷贝。</li></ul><h2 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h2><p>现代操作系统，通过虚拟内存技术，每个进程都有独立的虚拟内存空间，分别映射到不同的物理空间，不影响相互的使用。</p><p>共享内存通过使用一片虚拟地址空间，映射到相同的物理内存中，不需要发生拷贝问题，提高了进程间通信的速度。</p><h3 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h3><p>通过共享内存的方式解决了用户态和内核态拷贝问题，但是带来了多个进程读写同一个共享内存的的冲突问题。</p><p>为了防止多进程竞争共享资源，而造成的数据错乱，使用信号量来保护共享的资源任意时刻只被一个进程访问到。</p><p><strong>信号量是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据</strong>。</p><p>信号量表示<strong>资源的数量</strong>，控制信号量的有两种操作：</p><ul><li>P操作：信号量-1，之后如果信号量 &lt; 0，表示资源已被占用，需要阻塞等待；如果大于等于0，表示资源可以用，进程正常执行。</li><li>V操作：信号量+1，如果信号量仍然小于等于0，说明有阻塞中的进程，于是会唤醒进程执行（前面阻塞等待的）；否则表明当前没有阻塞的进程。</li></ul><p><img src="/../images/signal.png" alt="img"></p><blockquote><p>通过将资源信号量初始值设为1，作为互斥信号量。</p><ol><li>进程A在访问共享内存时，执行P操作，信号量 &#x3D; 0，说明资源可以访问</li><li>另一时刻，进程B也想访问共享内存，执行P操作，信号量 &#x3D; -1，说明资源已被占用，阻塞等待</li><li>A执行完后，执行V操作，信号量 &#x3D; 0，说明有进程阻塞等待访问共享内存，唤醒B执行</li><li>B执行完后，执行V操作，信号量 &#x3D; 1，结束。</li></ol></blockquote><p>此外，通过信号量也可以实现多进程同步方式，典型的例子生产者消费者模型。</p><p><img src="/../images/signal-2.png" alt="img"></p><blockquote><p>设置资信号量初始值为0</p><ul><li>如果进程B先消费，执行P操作，信号量 &#x3D; -1，阻塞等待</li><li>进程A生产数据，执行V操作，信号量 &#x3D; 0，说明有阻塞等待，唤醒B消费</li></ul></blockquote><h2 id="信号"><a href="#信号" class="headerlink" title="信号"></a>信号</h2><p>信号量时常规状态下的工作模式，对于异常模式下需要用<strong>信号</strong>来通知进程。</p><p>Linux提供了几十种信号，用于给进程发送信号。如果进程在后台运行，在知道进程PID号时，可以通过kill命令给进程发送信号。例如<code>kill -9 1050</code>，给PID为1050的进程发送SIGKILL信号，来结束进程。</p><p>信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。</p><p>信号是进程间通信机制中<strong>唯一的异步通信机制</strong>，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。</p><p><strong>1.执行默认操作</strong>。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。</p><p><strong>2.捕捉信号</strong>。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。</p><p><strong>3.忽略信号</strong>。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 <code>SIGKILL</code> 和 <code>SEGSTOP</code>，它们用于在任何时候中断或结束某一进程。</p><p>信号量和信号量并不是直接用于缓存进程间通信的数据。</p><h2 id="Socket"><a href="#Socket" class="headerlink" title="Socket"></a>Socket</h2><p>前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想<strong>跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。</strong></p><p>根据创建 socket 类型的不同，通信的方式也就不同：</p><ul><li>实现 TCP 字节流通信： socket 类型是 AF_INET 和 SOCK_STREAM；<ul><li>需要经过TCP三次握手，结束后需要通过close关闭</li><li>服务端监听一个socket用于接受客户端连接，accept后返回一个用于socket的通信的文件描述符</li></ul></li><li>实现 UDP 数据报通信：socket 类型是 AF_INET 和 SOCK_DGRAM；<ul><li>UDP 是没有连接的，所以不需要三次握手，也就不需要像 TCP 调用 listen 和 connect，但是 UDP 的交互仍然需要 IP 地址和端口号，因此也需要 bind。</li></ul></li><li>实现本地进程间通信<ul><li>通过绑定一个本地文件实现</li></ul></li></ul><h2 id="线程间通信"><a href="#线程间通信" class="headerlink" title="线程间通信"></a>线程间通信</h2><p>同个进程下的线程之间都是共享进程的资源，只要是共享变量都可以做到线程间通信，比如全局变量，所以对于线程间关注的不是通信方式，而是关注多线程竞争共享资源的问题，信号量也同样可以在线程间实现互斥与同步：</p><ul><li>互斥的方式，可保证任意时刻只有一个线程访问共享资源；</li><li>同步的方式，可保证线程 A 应在线程 B 之前执行。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git基本使用</title>
      <link href="/2023/03/29/7-Git/"/>
      <url>/2023/03/29/7-Git/</url>
      
        <content type="html"><![CDATA[<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><blockquote><p><a href="https://www.bilibili.com/list/watchlater?oid=528356813&bvid=BV1HM411377j&spm_id_from=..top_right_bar_window_view_later.content.click&p=9">GeekHour Git教程</a></p><p><a href="https://learngitbranching.js.org/?locale=zh_CN">菜就多练</a></p><p><a href="https://juejin.cn/post/6974184935804534815#heading-15">CSDN-工作中如何使用Git的</a></p><p><a href="https://www.ruanyifeng.com/blog/2015/12/git-workflow.html">阮一峰 Git 工作流程</a></p></blockquote><h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><pre class=" language-shell"><code class="language-shell"># 配置SSHssh-keygen -t rsa -C "这里换上你的邮箱，备注信息"# 不需要密码，直接三次回车# 生成id_rsa和id_rsa.pub# 添加公钥pub文件内容，到Settings -- SSH and GPG keyscat ~/.ssh/id_rsa.pub# 测试配置成功ssh -T git@github.com # 输入yesThe authenticity of host 'github.com (20.205.243.166)' can't be established.ED25519 key fingerprint is SHA256:+DiY3wvvV6TuJJhbpZisF/zLDA0zPMSvHdkr4UvCOqU.This key is not known by any other names.Are you sure you want to continue connecting (yes/no/[fingerprint])? yesWarning: Permanently added 'github.com' (ED25519) to the list of known hosts.Hi shixiaocaia! You've successfully authenticated, but GitHub does not provide shell access.# GitHub中添加SSH id_rsa.pub内容# 再次验证ssh -T git@github.com # Hi shixiaocaia! You've successfully authenticated, but GitHub does not provide shell access.</code></pre><ol><li>下载Git，Win&#x2F;Liunx…</li><li>配置用户信息</li></ol><pre class=" language-shell"><code class="language-shell"># 配置用户信息git config --global user.name "shixiaocaia"git config --global user.email shixiaocaia@gmail.comgit config --list</code></pre><ol start="3"><li>设置全局代理</li></ol><pre class=" language-shell"><code class="language-shell">git config --global http.proxy socks5://127.0.0.1:10808git config --global https.proxy socks5://127.0.0.1:10808</code></pre><ol start="4"><li>配置SSH</li></ol><pre class=" language-shell"><code class="language-shell">ssh-keygen -t rsa -C "这里换上你的邮箱"# 不需要密码，直接三次回车# 生成id_rsa和id_rsa.pub# 添加公钥pub文件内容，到Settings -- SSH and GPG keys# Linux下显示私钥内容cat ~/.ssh/id_rsa.pub# 测试配置成功ssh -T git@github.com # 输入yesThe authenticity of host 'github.com (20.205.243.166)' can't be established.ED25519 key fingerprint is SHA256:+DiY3wvvV6TuJJhbpZisF/zLDA0zPMSvHdkr4UvCOqU.This key is not known by any other names.Are you sure you want to continue connecting (yes/no/[fingerprint])? yesWarning: Permanently added 'github.com' (ED25519) to the list of known hosts.Hi shixiaocaia! You've successfully authenticated, but GitHub does not provide shell access.# GitHub中添加SSH id_rsa.pub内容# 再次验证ssh -T git@github.com # Hi shixiaocaia! You've successfully authenticated, but GitHub does not provide shell access.</code></pre><h2 id="工作区域"><a href="#工作区域" class="headerlink" title="工作区域"></a>工作区域</h2><p><img src="/../images/git-1.png" alt="0bc63cb7-4c90-4680-8749-9091a262b19c"><br><img src="/../images/git-2.png" alt="6f8f53a3-1bf8-499a-967f-28758e0993ec"></p><ul><li>workspace：工作区，实际操作的目录；</li><li>staging area &#x2F; index：暂存区，临时存放修改，通过<code>git add</code>命令添加工作区文件到暂存区；</li><li>local Repository：本地仓库，通过<code>git commit</code> 提交暂存区内容，会进入本地仓库；</li><li>Remote Repository：远程仓库，用来托管代码。</li></ul><hr><p><img src="/../images/git-3.png" alt="a528f4cb-9d53-40a7-bcda-23433dfbe999"></p><ul><li><p>一开始创建文件，是未跟踪状态，通过<code>git add .</code>添加到暂存区，每次修改后都需要<code>git add . </code>添加到暂存区</p></li><li><p><code>git ls-files</code>查看暂存区内容</p></li><li><p><code>git commit</code>提交暂存区的内容到本地仓库</p><ul><li>不会提交工作区内的内容，所以需要先<code>git add.</code>添加所有文件到暂存区，再提交</li><li><code>git commit -m &quot;your message&quot;</code>，记录备注信息</li></ul></li><li><p><code>git log</code>查看commit记录，<code>git log --oneline</code>查看简洁提交记录</p></li><li><p><code>git reflog</code></p><pre class=" language-shell"><code class="language-shell">$ git reflog8718541 (HEAD -> main) HEAD@&#123;0&#125;: reset: moving to 87185414b36cf347c173d0063a721ebf7a9e57378718541 (HEAD -> main) HEAD@&#123;1&#125;: reset: moving to 87185414b36cf347c173d0063a721ebf7a9e57378718541 (HEAD -> main) HEAD@&#123;2&#125;: commit: tt884fc87 HEAD@&#123;3&#125;: commit: test2c7d1abc HEAD@&#123;4&#125;: commit: test8bbcf7c HEAD@&#123;5&#125;: reset: moving to HEAD8bbcf7c HEAD@&#123;6&#125;: commit (amend): test2</code></pre><ul><li>输出<code>HEAD@&#123;6&#125;</code>，是相对当前时间的索引位置，越大数字代表越早的操作，可以用<code>HEAD@&#123;6&#125;</code>或者8718541哈希值来定位</li></ul></li><li><p><code>git reset</code>回退到某一个版本，默认上一个版本</p><ul><li>–soft，保留工作区和暂存区</li><li>–hard，删除两个版本之间工作区和暂存区的内容</li><li>–mixed，只保留工作区内容，清空暂存区内容</li><li>指令后面跟上版本号，比如<code>git reset --hard 234asda</code></li><li>如果误操作了Git，可以通过<code>git reflog</code>查看操作的历史记录，使用<code>git reset --hard 234asda</code>回退误操作之前的命令</li></ul></li><li><p><code>git diff</code>默认查看工作区和暂存区之间的差异内容</p><ul><li><code>git diff HEAD</code>查看工作区和最新提交之间的之间的差异</li><li><code>git diff --cached</code>查看工作区和版本库之间的差异</li><li><code>git diff 234asd 123asda</code> 比较不同提交的差异，或者比较提交和HEAD的差异</li><li><code>git diff HEAD~ HEAD</code> 查看当前提交和上一个提交的差异，波浪线后可以加数字表示前几个版本</li></ul></li><li><p>删除操作，先删除本地文件，再提交，删除暂存区的记录</p><ul><li><code>git rm &lt;file&gt;</code>，同时删除工作区和暂存区记录</li><li><code>git rm --cached &lt;file&gt;</code>删除暂存区记录</li><li>删除后记得提交</li></ul></li></ul><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><h3 id="init"><a href="#init" class="headerlink" title="init"></a>init</h3><pre class=" language-shell"><code class="language-shell">git init# 拉取项目git clone <URL>git remote add origin url / ssh# 使用ssh连接不需要登陆验证git pull -u origin main# 拉取origin的main分支到本地main分支# -u 将远程仓库和本地仓库关联起来</code></pre><ul><li>如果使用git clone同步项目到本地，而上述更多是从直接将本地文件夹与远端仓库建立连接</li><li>初始化后的.git文件夹，通过<code>ls -a</code>显示，包含了仓库的信息，一般隐藏避免删除</li><li><code>git remote -v</code>获取远程仓库信息</li></ul><h3 id="commit"><a href="#commit" class="headerlink" title="commit"></a>commit</h3><pre class=" language-shell"><code class="language-shell"># 提交暂存的更改，会新开编辑器进行编辑git commit # 提交暂存的更改，并记录下备注git commit -m "you message"# 等同于 git add . && git commit -mgit commit -am# 对最近一次的提交的信息进行修改,此操作会修改commit的hash值git commit --amend</code></pre><h3 id="branch"><a href="#branch" class="headerlink" title="branch"></a>branch</h3><pre class=" language-shell"><code class="language-shell"># 查看本地分支git branch# 查看远程分支git branch -r# 查看所有分支git branch -a# 切换到test分支git checkout test# 推荐使用switch切换分支，checkout具有恢复功能，容易引起误解git switch test# 创建分支git branch hello# 创建并切换分支git branch -b main# 删除分支git branch -d local_branch_namegit branch origin :remote_branch_name# :表示删除# 如果是未被合并的命令，需要通过-D来强制删除# 重命名分支git branch -m <old-branch-name> <new-branch-name># 查看分支属于哪部分拉出来的git reflog --date=local | grep <branchname> </code></pre><h3 id="pull"><a href="#pull" class="headerlink" title="pull"></a>pull</h3><pre class=" language-shell"><code class="language-shell"># 拉取最新的origin代码git fetch# 拉取并更新本地git fetch origin main:local_branch# 基于某个远程分支创建新的本地分支git checkout -b main origin/main</code></pre><h3 id="push-VS-fetch"><a href="#push-VS-fetch" class="headerlink" title="push VS fetch"></a>push VS fetch</h3><pre class=" language-shell"><code class="language-shell"># 拉取最新远程代码到本地，获取特定分支变化git fetch <远程主机名> <分支名># 合并最新代码git merge origin/main# git pull = git fetch & git merge origin maingit pull <远程主机名> <本地分支名>:<远程分支名># 一般本地分支名和远程分支名相同时，合并分支名# 用rebase 替代 merge，保证公共代码合并到当前分支是线性的git pull --rebase</code></pre><ul><li>在实际中进行PR之前，需要fetch最新的，然后rebase origin&#x2F;main，将分支变基到目标分支的最新版本，以便包含最新的变更</li><li>如果过程中产生冲突，按序解决<ul><li>处理产生冲突的文件</li><li>git add 文件名，标记处理完的文件，这里会创建一个虚拟提交，不需要手动的commit</li><li>git rebase –continue，这个过程中是一个个处理变基commit，可能发生多次冲突。继续执行rebase操作，重复执行</li><li>git push origin test_branch –force，处理完成后</li></ul></li></ul><h3 id="gitignore"><a href="#gitignore" class="headerlink" title="gitignore"></a>gitignore</h3><pre class=" language-shell"><code class="language-shell">touch .gitignoregit rm  --cached xxx# 添加 xxx/git commit -m"gitignore"git push origin main</code></pre><ul><li>哪些文件应该被忽略<ul><li>系统或者软件自动生成的文件</li><li>编译产生的中间文件和结果文件</li><li>运行时生成的日志文件、缓存文件、临时文件</li><li>涉及身份、密码、口令、密钥等敏感信息文件</li></ul></li><li>将需要忽略的文件写入到gitignore文件当中，<strong>如果文件已经存在版本库当中，需要先删除，才能生效</strong><ul><li>git rm  –cached xxx删除记录，删除暂存区内文件</li></ul></li><li>根据官方的gitignore的不同语言版本进行修改</li></ul><h3 id="merge-VS-rebase"><a href="#merge-VS-rebase" class="headerlink" title="merge VS rebase"></a>merge VS rebase</h3><pre class=" language-shell"><code class="language-shell">     D---E test    /A---B---C---F master</code></pre><ul><li><p>git merge</p><pre class=" language-shell"><code class="language-shell">     D--------E    /          \A---B---C---F---G    test , master</code></pre><ul><li>当产生冲突时，需要处理冲突部分文件，再重新提交merge后的结果（<code>git add  + commit</code>冲突文件），会生成一次提交G</li><li>融合代码到公共分支时使用git merge，而不是git rebase</li></ul></li><li><p>git rebase</p><pre class=" language-shell"><code class="language-shell"> A---B---D---E---C `---F` test , master</code></pre><ul><li>在master下执行rebase，会以master为合并后的分支，将test分支内容以交界点变基到master上，老的提交没有销毁不能再被访问或者使用；</li><li>产生冲突需要逐个处理，<code>git add .</code> <code>git rebase -continue</code>，或者<code>git rebase -skip</code>忽略当前冲突；</li><li>rebase后当前分支会与线上分支不同（加入了新的commit），需要<code>--force</code>强制；</li><li><code>git rebase -i HEAD~4</code>，用于合并多次提交记录，注意是从上往下；</li><li>融合代码到个人分支时候使用<code>git rebase</code>，可以不污染分支的提交记录，形成简洁的线性提交历史记录。</li></ul></li><li><p>git rebase和git merge区别</p><ul><li>git merge不会破坏原分支的提交记录，方便回溯和查看，缺点是产生额外的提交节点，分支图比较复杂；</li><li>git rebase不需要新增额外的提交记录，形成<strong>线性历史</strong>，直观和干净。缺点会改变提交历史，需要处理多次冲突问题；</li><li>公共代码–&gt;个人分支：git rebase，线性提交记录；个人分支–&gt;公共代码：git merge；</li></ul></li><li><p>常见的公共分支，master分支，feature是个人分支</p></li></ul><h3 id="git-cherry-pick"><a href="#git-cherry-pick" class="headerlink" title="git cherry-pick"></a>git cherry-pick</h3><ul><li>用于获取某个分支的单个提交，引入到当前分支来，可以同时合并多个，不连续的分支</li><li>其实可以基于rebase实现一部分</li></ul><h3 id="reset-VS-revert"><a href="#reset-VS-revert" class="headerlink" title="reset VS revert"></a>reset VS revert</h3><p><code>git reset</code>回退到某一个版本，默认上一个版本</p><ul><li>–soft，保留工作区和暂存区</li><li>–hard，删除两个版本之间工作区和暂存区的内容</li><li>–mixed，只保留工作区内容，清空暂存区内容</li><li>指令后面跟上版本号，比如<code>git reset --hard 234asda</code></li><li>如果误操作了Git，可以通过<code>git reflog</code>查看操作的历史记录，使用<code>git reset --hard 234asda</code>回退误操作之前的命令</li></ul><p><code>git revert</code>撤销某一次commit，同时新增一条commit记录，reset过于暴力。</p><p>对于个人的 feature 分支而言，可以使用 <code>git reset</code> 来回退历史记录，之后使用 <code>git push --force</code> 进行推送到远程</p><p>但是如果是在多人协作的集成分支上，不推荐直接使用 <code>git reset</code> 命令，而是使用更加安全的 <code>git revert</code> 命令进行撤回提交。这样，提交的历史记录不会被抹去，可以安全的进行撤回。</p><h3 id="git-stash"><a href="#git-stash" class="headerlink" title="git stash"></a>git stash</h3><p>用于切换不同分支时，在不提交的前提下，临时保存到暂存区。</p><pre class=" language-shell"><code class="language-shell">git stash //把本地的改动暂存起来git stash save "message" 执行存储时，添加备注，方便查找。git stash pop // 应用最近一次暂存的修改，并删除暂存的记录git stash apply  // 应用某个存储,但不会把存储从存储列表中删除，默认使用第一个存储,即 stash@&#123;0&#125;，如果要使用其他个，git stash apply stash@&#123;$num&#125; 。git stash list // 查看 stash 有哪些存储git stash clear // 删除所有缓存的 stash</code></pre><h3 id="不同工作取得撤销更改"><a href="#不同工作取得撤销更改" class="headerlink" title="不同工作取得撤销更改"></a>不同工作取得撤销更改</h3><ul><li>git status查看当前状态，修改、跟踪情况</li><li>git checkout –<filename>，撤回工作区的修改</li><li>git reset <filename>，撤回暂存区修改，</li></ul><h2 id="Git-flow"><a href="#Git-flow" class="headerlink" title="Git flow"></a>Git flow</h2><p><img src="/../images/git-5.webp" alt="img"></p><ul><li>主要分支<ul><li>main&#x2F;master分支：可以部署发布</li><li>develop分支：最新开发状态</li></ul></li><li>辅助分支<ul><li>feature：<strong>开发新功能</strong>的分支, 基于 develop, 完成后 merge 回 develop；</li><li>release：辅助版本发布的分支, 用来<strong>测试修复</strong> bug，基于 develop, 完成后 merge 回 develop 和 master</li><li>hotfix：<strong>修复 main 上的问题</strong>,  基于 master, 完成后 merge 回 master 和 develop</li></ul></li><li>GitFlow模型分支管理严格，代码合并清晰，适合中大型团队使用，但是分支流程过多较为复杂</li></ul><h2 id="Github-flow"><a href="#Github-flow" class="headerlink" title="Github flow"></a>Github flow</h2><p><img src="/../images/git6.png" alt="img"></p><ul><li>主要维护一个主分支master&#x2F;main，是随时可以部署发布的内容</li><li>需求新增基于master分支，合并到master分支需要PR，master分支内容一经合并，可以立即部署使用</li><li>相比前者分支足够简单，但不适合多版本产品线使用</li></ul><h2 id="Gitlab-flow"><a href="#Gitlab-flow" class="headerlink" title="Gitlab flow"></a>Gitlab flow</h2><p>结合上述优点，既有适应不同开发环境的弹性，又有单一主分支的简单和便利。</p><p>主要包含两种方式，持续发布和版本发布。</p><p>持续发布主要是在master分支的基础上建立了pre-producition，production分支，master是pre-production的上游，反之下游，开发过程中不断递进发布，从上游到下游。只有紧急情况才会跳过上游。</p><p>版本发布建议的做法是每一个稳定版本，都要从<code>master</code>分支拉出一个分支，比如<code>2-3-stable</code>、<code>2-4-stable</code>等等。以后，只有修补bug，才允许将代码合并到这些分支，并且此时要更新小版本号。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 是什么 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello Hexo</title>
      <link href="/2023/02/02/0-Hello%20World/"/>
      <url>/2023/02/02/0-Hello%20World/</url>
      
        <content type="html"><![CDATA[<h2 id="npm安装"><a href="#npm安装" class="headerlink" title="npm安装"></a>npm安装</h2><p>前往<a href="https://nodejs.org/en">Node.js官网</a>选择合适版本</p><h2 id="Hexo环境配置"><a href="#Hexo环境配置" class="headerlink" title="Hexo环境配置"></a>Hexo环境配置</h2><pre class=" language-shell"><code class="language-shell">npm install hexo-cli -ghexo init blogcd blognpm installhexo server</code></pre><h2 id="Hexo基本用法"><a href="#Hexo基本用法" class="headerlink" title="Hexo基本用法"></a>Hexo基本用法</h2><pre class=" language-shell"><code class="language-shell">hexo server # 本地模拟hexo new "new post" # 新建一篇文章hexo clean # 清空缓存</code></pre><h2 id="修改主题"><a href="#修改主题" class="headerlink" title="修改主题"></a>修改主题</h2><p>取决于你自己。</p><p>本博客主题<a href="https://minimalism.codeover.cn/docs/config/image">Minimalism</a>。</p><p>修改配置文件后，务必清除缓存使配置生效</p><pre class=" language-shell"><code class="language-shell">npm run clean</code></pre><h2 id="部署到Github"><a href="#部署到Github" class="headerlink" title="部署到Github"></a>部署到Github</h2><blockquote><p>注意您上传的项目名称应为<code>username.github.io</code></p></blockquote><ol><li>hexo-deployer-git插件</li></ol><pre class=" language-shell"><code class="language-shell">npm install --save hexo-deployer-git</code></pre><ol start="2"><li>修改_config.yml文件</li></ol><pre class=" language-shell"><code class="language-shell">deploy:  type: git  repo: xxx.git  branch: page # 部署到page分支</code></pre><ol start="3"><li>发布到github</li></ol><pre class=" language-shell"><code class="language-shell">hexo cl # clear cachehexo g # 生成publichexo d# deploy</code></pre><ol start="4"><li>修改setting设置中的page中分支为上述分支。</li></ol><blockquote><p>开始你的✍吧</p></blockquote><h2 id="补充问题"><a href="#补充问题" class="headerlink" title="补充问题"></a>补充问题</h2><h3 id="同步theme"><a href="#同步theme" class="headerlink" title="同步theme"></a>同步theme</h3><p>在更换设备后重新拉取项目时，并不会直接拉取theme下的子内容</p><pre class=" language-shell"><code class="language-shell">git submodule initgit submodule update</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Hello world </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
